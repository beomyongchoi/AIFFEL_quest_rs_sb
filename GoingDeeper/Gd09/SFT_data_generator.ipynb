{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400438de-1620-4728-baed-1ec9337510e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "# OpenAI API 설정\n",
    "openai.api_key = \"your-api-key-here\"  # 여기에 실제 API 키를 입력하세요\n",
    "\n",
    "class CompletionReplacer:\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4o\"):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.client = openai.OpenAI(api_key=api_key)\n",
    "    \n",
    "    def load_jsonl_data(self, file_path: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"JSONL 파일을 읽어서 데이터를 로드합니다.\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "            # JSON 배열 형태인 경우\n",
    "            if content.startswith('[') and content.endswith(']'):\n",
    "                return json.loads(content)\n",
    "            # JSONL 형태인 경우\n",
    "            else:\n",
    "                data = []\n",
    "                for line in content.split('\\n'):\n",
    "                    if line.strip():\n",
    "                        data.append(json.loads(line))\n",
    "                return data\n",
    "    \n",
    "    def generate_completion(self, prompt: str, system_prompt: str = None) -> str:\n",
    "        \"\"\"단일 프롬프트에 대해 OpenAI API를 사용해 응답을 생성합니다.\"\"\"\n",
    "        try:\n",
    "            messages = []\n",
    "            if system_prompt:\n",
    "                messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                max_tokens=500,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content.strip()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"API 호출 중 오류 발생: {e}\")\n",
    "            return f\"오류: {str(e)}\"\n",
    "    \n",
    "    def count_tokens_approximate(self, text: str) -> int:\n",
    "        \"\"\"토큰 수를 대략적으로 계산합니다.\"\"\"\n",
    "        # 한국어의 경우 대략 1.5-2자당 1토큰으로 추정\n",
    "        return len(text) // 1.5\n",
    "    \n",
    "    def process_data(self, data: List[Dict[str, Any]], system_prompt: str = None, delay: float = 1.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"전체 데이터를 처리해서 새로운 completion을 생성합니다.\"\"\"\n",
    "        processed_data = []\n",
    "        \n",
    "        for i, item in enumerate(data):\n",
    "            print(f\"처리 중... {i+1}/{len(data)}: {item['prompt'][:30]}...\")\n",
    "            \n",
    "            # 새로운 completion 생성\n",
    "            new_completion = self.generate_completion(item['prompt'], system_prompt)\n",
    "            \n",
    "            # 새로운 토큰 수 계산\n",
    "            new_tokens = int(self.count_tokens_approximate(new_completion))\n",
    "            \n",
    "            # 새로운 데이터 생성\n",
    "            new_item = {\n",
    "                \"prompt\": item['prompt'],\n",
    "                \"completion\": new_completion,\n",
    "                \"tokens\": new_tokens\n",
    "            }\n",
    "            \n",
    "            processed_data.append(new_item)\n",
    "            \n",
    "            # API rate limit 방지를 위한 딜레이\n",
    "            time.sleep(delay)\n",
    "        \n",
    "        return processed_data\n",
    "    \n",
    "    def save_results(self, data: List[Dict[str, Any]], output_path: str, format_type: str = \"json\"):\n",
    "        \"\"\"결과를 파일로 저장합니다.\"\"\"\n",
    "        if format_type == \"jsonl\":\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                for item in data:\n",
    "                    f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "        else:  # JSON 배열 형태\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"결과가 {output_path}에 저장되었습니다.\")\n",
    "\n",
    "# 사용 예시 - 다양한 최신 모델 옵션\n",
    "def main():\n",
    "    API_KEY = \"your-openai-api-key-here\"  # 실제 API 키로 변경\n",
    "    INPUT_FILE = \"kochatgpt_1_SFT.jsonl\"\n",
    "    OUTPUT_FILE = \"kochatgpt_1_SFT_updated.json\"\n",
    "    \n",
    "    # 최신 모델 선택 옵션들:\n",
    "    # \"gpt-4o\" - 최신 GPT-4 Omni (추천)\n",
    "    # \"gpt-4-turbo\" - GPT-4 Turbo \n",
    "    # \"gpt-4o-mini\" - 더 빠르고 저렴한 버전\n",
    "    # \"o1-preview\" - OpenAI o1 모델 (추론 특화)\n",
    "    # \"o1-mini\" - o1의 더 빠른 버전\n",
    "    \n",
    "    SELECTED_MODEL = \"gpt-4o\"  # 원하는 모델로 변경하세요\n",
    "    \n",
    "    # 시스템 프롬프트 (선택사항)\n",
    "    SYSTEM_PROMPT = \"\"\"당신은 도움이 되고 친근한 한국어 AI 어시스턴트입니다. \n",
    "사용자의 질문에 정확하고 유용한 답변을 제공해주세요. \n",
    "답변은 자연스럽고 이해하기 쉽게 작성해주세요.\"\"\"\n",
    "    \n",
    "    # CompletionReplacer 인스턴스 생성 (선택한 모델 사용)\n",
    "    replacer = CompletionReplacer(API_KEY, model=SELECTED_MODEL)\n",
    "    \n",
    "    try:\n",
    "        # 1. 기존 데이터 로드\n",
    "        print(\"기존 데이터를 로드하는 중...\")\n",
    "        original_data = replacer.load_jsonl_data(INPUT_FILE)\n",
    "        print(f\"총 {len(original_data)}개의 항목을 발견했습니다.\")\n",
    "        \n",
    "        # 2. 새로운 completion 생성\n",
    "        print(\"OpenAI API를 사용해 새로운 응답을 생성하는 중...\")\n",
    "        updated_data = replacer.process_data(\n",
    "            original_data, \n",
    "            system_prompt=SYSTEM_PROMPT,\n",
    "            delay=1.0  # 1초 딜레이\n",
    "        )\n",
    "        \n",
    "        # 3. 결과 저장\n",
    "        replacer.save_results(updated_data, OUTPUT_FILE)\n",
    "        \n",
    "        # 4. 간단한 결과 출력\n",
    "        print(\"\\n=== 처리 완료 ===\")\n",
    "        print(f\"총 {len(updated_data)}개 항목이 처리되었습니다.\")\n",
    "        print(f\"평균 토큰 수: {sum(item['tokens'] for item in updated_data) / len(updated_data):.1f}\")\n",
    "        \n",
    "        # 첫 번째 예시 출력\n",
    "        if updated_data:\n",
    "            print(f\"\\n=== 첫 번째 항목 예시 ===\")\n",
    "            print(f\"프롬프트: {updated_data[0]['prompt']}\")\n",
    "            print(f\"새로운 응답: {updated_data[0]['completion'][:100]}...\")\n",
    "            print(f\"토큰 수: {updated_data[0]['tokens']}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"처리 중 오류 발생: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# 비동기 버전 (더 빠른 처리를 원하는 경우)\n",
    "class AsyncCompletionReplacer:\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4o\", max_concurrent: int = 5):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.max_concurrent = max_concurrent\n",
    "        self.semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    \n",
    "    async def generate_completion_async(self, session: aiohttp.ClientSession, prompt: str, system_prompt: str = None) -> str:\n",
    "        \"\"\"비동기로 completion을 생성합니다.\"\"\"\n",
    "        async with self.semaphore:\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            \n",
    "            messages = []\n",
    "            if system_prompt:\n",
    "                messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "            \n",
    "            payload = {\n",
    "                \"model\": self.model,\n",
    "                \"messages\": messages,\n",
    "                \"max_tokens\": 500,\n",
    "                \"temperature\": 0.7\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                async with session.post(\n",
    "                    \"https://api.openai.com/v1/chat/completions\",\n",
    "                    headers=headers,\n",
    "                    json=payload\n",
    "                ) as response:\n",
    "                    result = await response.json()\n",
    "                    return result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            except Exception as e:\n",
    "                return f\"오류: {str(e)}\"\n",
    "    \n",
    "    async def process_data_async(self, data: List[Dict[str, Any]], system_prompt: str = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"비동기로 전체 데이터를 처리합니다.\"\"\"\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = []\n",
    "            for item in data:\n",
    "                task = self.generate_completion_async(session, item['prompt'], system_prompt)\n",
    "                tasks.append(task)\n",
    "            \n",
    "            print(\"모든 API 호출을 시작합니다...\")\n",
    "            new_completions = await asyncio.gather(*tasks)\n",
    "            \n",
    "            processed_data = []\n",
    "            for i, (item, new_completion) in enumerate(zip(data, new_completions)):\n",
    "                new_tokens = int(len(new_completion) // 1.5)\n",
    "                \n",
    "                new_item = {\n",
    "                    \"prompt\": item['prompt'],\n",
    "                    \"completion\": new_completion,\n",
    "                    \"tokens\": new_tokens\n",
    "                }\n",
    "                processed_data.append(new_item)\n",
    "            \n",
    "            return processed_data\n",
    "\n",
    "# 비동기 버전 사용 예시 (최신 모델)\n",
    "async def main_async():\n",
    "    API_KEY = \"your-openai-api-key-here\"\n",
    "    INPUT_FILE = \"kochatgpt_1_SFT.jsonl\"\n",
    "    OUTPUT_FILE = \"kochatgpt_1_SFT_updated_async.json\"\n",
    "    \n",
    "    # 최신 모델 선택 - 비동기 처리에는 더 빠른 모델 추천\n",
    "    SELECTED_MODEL = \"gpt-4o-mini\"  # 빠르고 효율적\n",
    "    \n",
    "    replacer = AsyncCompletionReplacer(API_KEY, model=SELECTED_MODEL, max_concurrent=3)\n",
    "    \n",
    "    # 동기 버전의 replacer로 데이터 로드\n",
    "    sync_replacer = CompletionReplacer(API_KEY)\n",
    "    original_data = sync_replacer.load_jsonl_data(INPUT_FILE)\n",
    "    \n",
    "    # 비동기 처리\n",
    "    updated_data = await replacer.process_data_async(original_data)\n",
    "    \n",
    "    # 저장\n",
    "    sync_replacer.save_results(updated_data, OUTPUT_FILE)\n",
    "\n",
    "# 비동기 실행하려면:\n",
    "# asyncio.run(main_async())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
