{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334bbef5-4873-4c28-9c12-06cecdb14e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class RMOpenAIEnhancer:\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4o\"):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.client = openai.OpenAI(api_key=api_key)\n",
    "    \n",
    "    def load_rm_data(self, file_path: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"RM JSONL 파일을 읽어서 데이터를 로드합니다.\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "            # JSON 배열 형태인 경우\n",
    "            if content.startswith('[') and content.endswith(']'):\n",
    "                return json.loads(content)\n",
    "            # JSONL 형태인 경우\n",
    "            else:\n",
    "                data = []\n",
    "                for line in content.split('\\n'):\n",
    "                    if line.strip():\n",
    "                        data.append(json.loads(line))\n",
    "                return data\n",
    "    \n",
    "    def generate_openai_completion(self, prompt: str, system_prompt: str = None) -> str:\n",
    "        \"\"\"OpenAI API를 사용해 응답을 생성합니다.\"\"\"\n",
    "        try:\n",
    "            messages = []\n",
    "            if system_prompt:\n",
    "                messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                max_tokens=500,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content.strip()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"API 호출 중 오류 발생: {e}\")\n",
    "            return f\"오류: {str(e)}\"\n",
    "    \n",
    "    def shift_rankings(self, ranking: List[int]) -> List[int]:\n",
    "        \"\"\"기존 랭킹을 한 단계씩 뒤로 밀기 (0->1, 1->2, 2->3)\"\"\"\n",
    "        return [rank + 1 for rank in ranking]\n",
    "    \n",
    "    def process_rm_data(self, data: List[Dict[str, Any]], system_prompt: str = None, delay: float = 1.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"RM 데이터에 OpenAI completion과 새로운 랭킹을 추가합니다.\"\"\"\n",
    "        processed_data = []\n",
    "        \n",
    "        for i, item in enumerate(data):\n",
    "            print(f\"처리 중... {i+1}/{len(data)}: {item['prompt'][:30]}...\")\n",
    "            \n",
    "            # OpenAI API로 새로운 completion 생성\n",
    "            new_completion = self.generate_openai_completion(item['prompt'], system_prompt)\n",
    "            \n",
    "            # 기존 랭킹을 한 단계씩 뒤로 밀기\n",
    "            shifted_ranking = self.shift_rankings(item['ranking'])\n",
    "            \n",
    "            # 새로운 completion_4를 0위(최고 순위)로 추가\n",
    "            new_ranking = shifted_ranking + [0]  # completion_4는 0위\n",
    "            \n",
    "            # 새로운 데이터 구성\n",
    "            new_item = {\n",
    "                \"prompt\": item['prompt'],\n",
    "                \"completion_0\": item['completion_0'],\n",
    "                \"completion_1\": item['completion_1'],\n",
    "                \"completion_2\": item['completion_2'],\n",
    "                \"completion_4\": new_completion,  # OpenAI API 응답\n",
    "                \"ranking\": new_ranking\n",
    "            }\n",
    "            \n",
    "            processed_data.append(new_item)\n",
    "            \n",
    "            # API rate limit 방지를 위한 딜레이\n",
    "            time.sleep(delay)\n",
    "        \n",
    "        return processed_data\n",
    "    \n",
    "    def save_results(self, data: List[Dict[str, Any]], output_path: str, format_type: str = \"json\"):\n",
    "        \"\"\"결과를 파일로 저장합니다.\"\"\"\n",
    "        if format_type == \"jsonl\":\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                for item in data:\n",
    "                    f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "        else:  # JSON 배열 형태\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"결과가 {output_path}에 저장되었습니다.\")\n",
    "    \n",
    "    def preview_changes(self, original_item: Dict[str, Any], new_item: Dict[str, Any]):\n",
    "        \"\"\"변경사항을 미리보기로 보여줍니다.\"\"\"\n",
    "        print(f\"프롬프트: {original_item['prompt']}\")\n",
    "        print(f\"원본 랭킹: {original_item['ranking']}\")\n",
    "        print(f\"새로운 랭킹: {new_item['ranking']}\")\n",
    "        print(f\"추가된 completion_4: {new_item['completion_4'][:80]}...\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def main():\n",
    "    # 설정\n",
    "    API_KEY = \"your-openai-api-key-here\"  # 실제 API 키로 변경\n",
    "    INPUT_FILE = \"kochatgpt_2_RM.jsonl\"\n",
    "    OUTPUT_FILE = \"kochatgpt_2_RM_enhanced.json\"\n",
    "    \n",
    "    # 최신 모델 선택\n",
    "    SELECTED_MODEL = \"gpt-4o\"  # 또는 \"gpt-4o-mini\"\n",
    "    \n",
    "    # 시스템 프롬프트\n",
    "    SYSTEM_PROMPT = \"\"\"당신은 정확하고 도움이 되는 한국어 AI 어시스턴트입니다. \n",
    "사용자의 질문에 간결하고 정확한 답변을 제공해주세요. \n",
    "불확실한 정보에 대해서는 추측하지 말고 모른다고 답하세요.\"\"\"\n",
    "    \n",
    "    # RMOpenAIEnhancer 인스턴스 생성\n",
    "    enhancer = RMOpenAIEnhancer(API_KEY, model=SELECTED_MODEL)\n",
    "    \n",
    "    try:\n",
    "        # 1. 기존 RM 데이터 로드\n",
    "        print(\"기존 RM 데이터를 로드하는 중...\")\n",
    "        original_data = enhancer.load_rm_data(INPUT_FILE)\n",
    "        print(f\"총 {len(original_data)}개의 항목을 발견했습니다.\")\n",
    "        \n",
    "        # 2. OpenAI API로 completion_4 추가 및 랭킹 조정\n",
    "        print(\"OpenAI API를 사용해 새로운 응답을 생성하고 랭킹을 조정하는 중...\")\n",
    "        enhanced_data = enhancer.process_rm_data(\n",
    "            original_data, \n",
    "            system_prompt=SYSTEM_PROMPT,\n",
    "            delay=1.0  # 1초 딜레이\n",
    "        )\n",
    "        \n",
    "        # 3. 변경사항 미리보기 (첫 번째 항목만)\n",
    "        if enhanced_data:\n",
    "            print(\"\\n=== 첫 번째 항목 변경사항 미리보기 ===\")\n",
    "            enhancer.preview_changes(original_data[0], enhanced_data[0])\n",
    "        \n",
    "        # 4. 결과 저장\n",
    "        enhancer.save_results(enhanced_data, OUTPUT_FILE)\n",
    "        \n",
    "        # 5. 최종 결과 요약\n",
    "        print(\"\\n=== 처리 완료 ===\")\n",
    "        print(f\"총 {len(enhanced_data)}개 항목 처리 완료\")\n",
    "        print(\"변경사항:\")\n",
    "        print(\"- 기존 랭킹: 0, 1, 2 → 새로운 랭킹: 1, 2, 3\")\n",
    "        print(\"- completion_4 추가 (랭킹 0위 - 최고 순위)\")\n",
    "        print(\"- 새로운 랭킹 배열 길이: 4개\")\n",
    "        \n",
    "        # 랭킹 분포 확인\n",
    "        print(\"\\n=== 새로운 랭킹 구조 확인 ===\")\n",
    "        for i, item in enumerate(enhanced_data[:2]):  # 처음 2개만 보여주기\n",
    "            print(f\"{i+1}번째 항목:\")\n",
    "            print(f\"  completion_0: {item['ranking'][0]}위\")\n",
    "            print(f\"  completion_1: {item['ranking'][1]}위\") \n",
    "            print(f\"  completion_2: {item['ranking'][2]}위\")\n",
    "            print(f\"  completion_4: {item['ranking'][3]}위 (OpenAI)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"처리 중 오류 발생: {e}\")\n",
    "\n",
    "# 비동기 버전 (더 빠른 처리)\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "class AsyncRMOpenAIEnhancer:\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4o\", max_concurrent: int = 3):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.max_concurrent = max_concurrent\n",
    "        self.semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    \n",
    "    async def generate_openai_completion_async(self, session: aiohttp.ClientSession, prompt: str, system_prompt: str = None) -> str:\n",
    "        \"\"\"비동기로 OpenAI completion을 생성합니다.\"\"\"\n",
    "        async with self.semaphore:\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            \n",
    "            messages = []\n",
    "            if system_prompt:\n",
    "                messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "            \n",
    "            payload = {\n",
    "                \"model\": self.model,\n",
    "                \"messages\": messages,\n",
    "                \"max_tokens\": 500,\n",
    "                \"temperature\": 0.7\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                async with session.post(\n",
    "                    \"https://api.openai.com/v1/chat/completions\",\n",
    "                    headers=headers,\n",
    "                    json=payload\n",
    "                ) as response:\n",
    "                    result = await response.json()\n",
    "                    return result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            except Exception as e:\n",
    "                return f\"오류: {str(e)}\"\n",
    "    \n",
    "    async def process_rm_data_async(self, data: List[Dict[str, Any]], system_prompt: str = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"비동기로 RM 데이터를 처리합니다.\"\"\"\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = []\n",
    "            for item in data:\n",
    "                task = self.generate_openai_completion_async(session, item['prompt'], system_prompt)\n",
    "                tasks.append(task)\n",
    "            \n",
    "            print(\"모든 API 호출을 시작합니다...\")\n",
    "            new_completions = await asyncio.gather(*tasks)\n",
    "            \n",
    "            processed_data = []\n",
    "            for item, new_completion in zip(data, new_completions):\n",
    "                # 기존 랭킹을 한 단계씩 뒤로 밀기\n",
    "                shifted_ranking = [rank + 1 for rank in item['ranking']]\n",
    "                new_ranking = shifted_ranking + [0]  # completion_4는 0위\n",
    "                \n",
    "                new_item = {\n",
    "                    \"prompt\": item['prompt'],\n",
    "                    \"completion_0\": item['completion_0'],\n",
    "                    \"completion_1\": item['completion_1'],\n",
    "                    \"completion_2\": item['completion_2'],\n",
    "                    \"completion_4\": new_completion,\n",
    "                    \"ranking\": new_ranking\n",
    "                }\n",
    "                processed_data.append(new_item)\n",
    "            \n",
    "            return processed_data\n",
    "\n",
    "# 비동기 실행 함수\n",
    "async def main_async():\n",
    "    API_KEY = \"your-openai-api-key-here\"\n",
    "    INPUT_FILE = \"kochatgpt_2_RM.jsonl\"\n",
    "    OUTPUT_FILE = \"kochatgpt_2_RM_enhanced_async.json\"\n",
    "    \n",
    "    SELECTED_MODEL = \"gpt-4o-mini\"  # 더 빠른 처리를 위해\n",
    "    \n",
    "    enhancer = AsyncRMOpenAIEnhancer(API_KEY, model=SELECTED_MODEL, max_concurrent=3)\n",
    "    \n",
    "    # 동기 버전으로 데이터 로드\n",
    "    sync_enhancer = RMOpenAIEnhancer(API_KEY, model=SELECTED_MODEL)\n",
    "    original_data = sync_enhancer.load_rm_data(INPUT_FILE)\n",
    "    \n",
    "    # 비동기 처리\n",
    "    enhanced_data = await enhancer.process_rm_data_async(original_data)\n",
    "    \n",
    "    # 저장\n",
    "    sync_enhancer.save_results(enhanced_data, OUTPUT_FILE)\n",
    "\n",
    "# Jupyter에서 실행하려면:\n",
    "# await main_async()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
