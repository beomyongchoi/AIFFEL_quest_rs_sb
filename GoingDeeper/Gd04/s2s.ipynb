{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b700c0-b7c7-40a1-b292-d1ee10f934d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt-get install -y fonts-nanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1adf526-b089-43b3-ad72-56f45d954cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.ticker as ticker\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.ERROR)\n",
    "\n",
    "# fontpath = \"/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf\"\n",
    "# fontprop = fm.FontProperties(fname=fontpath, size=12)\n",
    "# plt.rcParams[\"font.family\"] = fontprop.get_name()\n",
    "\n",
    "# print(f\"설정된 폰트: {fontprop.get_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54be68af-328b-4b56-af7a-6eebf73cd9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece # 미리 설치 안하면 아래에서 오류가 남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676042be-be34-449e-af97-8a98b62dc377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "109159a5-443a-41ca-bb32-6a4c531d36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_korean(sentence):\n",
    "#     sentence = sentence.strip()\n",
    "#     sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "#     sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "#     sentence = re.sub(r\"[^가-힣a-zA-Z0-9?.!,\\s]+\", \" \", sentence)\n",
    "#     sentence = sentence.strip()\n",
    "#     return sentence\n",
    "\n",
    "# print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d23cfdf8-fb3b-4d21-9719-55cf41f1817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "def preprocess_korean(sentence):\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    # sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^가-힣a-zA-Z?.!,\\s]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8732b4ad-bbd9-4f9e-bcd5-d2fb1ec0ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94cc4c85-0f22-4cf1-a0b5-55035379aaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "def preprocess_english(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    return sentence\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19f448ae-dc95-40f7-8afd-efc6bf626249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(ko_file_path, en_file_path, max_samples=None):\n",
    "    \"\"\"\n",
    "    한국어-영어 병렬 데이터를 로드하고 전처리하는 함수\n",
    "    \n",
    "    Args:\n",
    "        ko_file_path: 한국어 파일 경로\n",
    "        en_file_path: 영어 파일 경로\n",
    "        max_samples: 최대 샘플 수 (None이면 전체)\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: 전처리된 데이터프레임\n",
    "    \"\"\"\n",
    "    \n",
    "    # 파일 읽기\n",
    "    with open(ko_file_path, 'r', encoding='utf-8') as f:\n",
    "        ko_lines = f.readlines()\n",
    "    \n",
    "    with open(en_file_path, 'r', encoding='utf-8') as f:\n",
    "        en_lines = f.readlines()\n",
    "    \n",
    "    # 줄 수 맞추기 (더 짧은 쪽에 맞춤)\n",
    "    min_len = min(len(ko_lines), len(en_lines))\n",
    "    ko_lines = ko_lines[:min_len]\n",
    "    en_lines = en_lines[:min_len]\n",
    "    \n",
    "    # 전처리 적용\n",
    "    ko_processed = [preprocess_korean(line) for line in ko_lines]\n",
    "    en_processed = [preprocess_english(line) for line in en_lines]\n",
    "    \n",
    "    # 빈 문장 제거\n",
    "    valid_pairs = []\n",
    "    for ko, en in zip(ko_processed, en_processed):\n",
    "        if ko.strip() and en.strip():  # 둘 다 비어있지 않은 경우만\n",
    "            valid_pairs.append((ko, en))\n",
    "    \n",
    "    # max_samples 적용\n",
    "    if max_samples and len(valid_pairs) > max_samples:\n",
    "        valid_pairs = valid_pairs[:max_samples]\n",
    "    \n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame(valid_pairs, columns=['korean', 'english'])\n",
    "    \n",
    "    print(f\"총 {len(df)} 개의 문장 쌍이 로드되었습니다.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd13c0d5-33aa-4f59-9ac3-2202f9c7b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corpus_files(df, ko_output_path=\"ko_corpus.txt\", en_output_path=\"en_corpus.txt\"):\n",
    "    \"\"\"\n",
    "    SentencePiece 훈련을 위한 코퍼스 파일 저장\n",
    "    \"\"\"\n",
    "    # 한국어 코퍼스 저장\n",
    "    df[\"korean\"].to_csv(ko_output_path, index=False, header=False, sep=\"\\n\", encoding=\"utf-8\")\n",
    "    \n",
    "    # 영어 코퍼스 저장  \n",
    "    df[\"english\"].to_csv(en_output_path, index=False, header=False, sep=\"\\n\", encoding=\"utf-8\")\n",
    "    \n",
    "    print(f\"코퍼스 파일이 저장되었습니다: {ko_output_path}, {en_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdffb991-5720-4978-820f-144b334e2f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 전처리 테스트 ===\n",
      "원본 한국어: 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
      "전처리 후: 개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?\n",
      "\n",
      "원본 영어: Much of personal computing is about \"can you top this?\"\n",
      "전처리 후: much of personal computing is about can you top this ?\n",
      "총 94100 개의 문장 쌍이 로드되었습니다.\n",
      "코퍼스 파일이 저장되었습니다: ko_corpus.txt, en_corpus.txt\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 샘플 데이터\n",
    "test_ko = \"개인용 컴퓨터 사용의 상당 부분은 \\\"이것보다 뛰어날 수 있느냐?\\\"\"\n",
    "test_en = \"Much of personal computing is about \\\"can you top this?\\\"\"\n",
    "\n",
    "print(\"=== 전처리 테스트 ===\")\n",
    "print(f\"원본 한국어: {test_ko}\")\n",
    "print(f\"전처리 후: {preprocess_korean(test_ko)}\")\n",
    "print()\n",
    "print(f\"원본 영어: {test_en}\")\n",
    "print(f\"전처리 후: {preprocess_english(test_en)}\")\n",
    "\n",
    "# 실제 사용 시:\n",
    "df = load_and_preprocess_data(\"korean-english-park.train.ko\", \n",
    "                              \"korean-english-park.train.en\", \n",
    "                              max_samples=None)\n",
    "save_corpus_files(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e9370e0-3333-42d8-8cb3-74ade915adba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ko_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: encoder_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: ko_corpus.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 94100 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=5732420\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=1207\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 94100 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=2527919\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 160898 seed sentencepieces\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 94100\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 197014\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 197014 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=85899 obj=12.5682 num_tokens=381859 num_tokens/piece=4.44544\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=71891 obj=11.4288 num_tokens=383205 num_tokens/piece=5.33036\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=53914 obj=11.4601 num_tokens=401037 num_tokens/piece=7.43846\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=53891 obj=11.4267 num_tokens=401125 num_tokens/piece=7.44327\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=40418 obj=11.5698 num_tokens=425634 num_tokens/piece=10.5308\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=40417 obj=11.5368 num_tokens=425638 num_tokens/piece=10.5312\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=30312 obj=11.7255 num_tokens=452828 num_tokens/piece=14.9389\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=30312 obj=11.6838 num_tokens=452818 num_tokens/piece=14.9386\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=22734 obj=11.9301 num_tokens=480177 num_tokens/piece=21.1215\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=22734 obj=11.8835 num_tokens=480306 num_tokens/piece=21.1272\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=17050 obj=12.1652 num_tokens=508580 num_tokens/piece=29.8287\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=17050 obj=12.112 num_tokens=508583 num_tokens/piece=29.8289\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=12787 obj=12.4334 num_tokens=537590 num_tokens/piece=42.0419\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=12787 obj=12.3741 num_tokens=537594 num_tokens/piece=42.0422\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9590 obj=12.7556 num_tokens=567494 num_tokens/piece=59.1756\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9590 obj=12.6853 num_tokens=567495 num_tokens/piece=59.1757\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8800 obj=12.8049 num_tokens=576239 num_tokens/piece=65.4817\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8800 obj=12.7846 num_tokens=576234 num_tokens/piece=65.4811\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: encoder_spm.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: encoder_spm.vocab\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: en_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: decoder_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: en_corpus.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 94100 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=11986060\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9865% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=29\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999865\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 94100 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=6839366\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 82992 seed sentencepieces\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 94100\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 44562\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 44562 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=35324 obj=9.84242 num_tokens=83380 num_tokens/piece=2.36043\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=26175 obj=7.98906 num_tokens=83792 num_tokens/piece=3.20122\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=19628 obj=7.91145 num_tokens=87295 num_tokens/piece=4.44747\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=19606 obj=7.8896 num_tokens=87363 num_tokens/piece=4.45593\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=14704 obj=7.92355 num_tokens=96073 num_tokens/piece=6.5338\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=14704 obj=7.91081 num_tokens=96135 num_tokens/piece=6.53802\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=11028 obj=7.98306 num_tokens=106169 num_tokens/piece=9.62722\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=11028 obj=7.96404 num_tokens=106157 num_tokens/piece=9.62613\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8800 obj=8.04885 num_tokens=114178 num_tokens/piece=12.9748\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8800 obj=8.02978 num_tokens=114154 num_tokens/piece=12.972\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: decoder_spm.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: decoder_spm.vocab\n"
     ]
    }
   ],
   "source": [
    "# vocab_size = 3000\n",
    "pad_id = 0\n",
    "bos_id = 1\n",
    "eos_id = 2\n",
    "unk_id = 3\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input = \"ko_corpus.txt\",\n",
    "    model_prefix = \"encoder_spm\",\n",
    "    # vocab_size = vocab_size,\n",
    "    pad_id = pad_id,\n",
    "    bos_id = bos_id,\n",
    "    eos_id = eos_id,\n",
    "    unk_id = unk_id\n",
    ")\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input = \"en_corpus.txt\",\n",
    "    model_prefix = \"decoder_spm\",\n",
    "    # vocab_size = vocab_size,\n",
    "    pad_id = pad_id,\n",
    "    bos_id = bos_id,\n",
    "    eos_id = eos_id,\n",
    "    unk_id = unk_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b3ffe78-0423-4e3f-95a2-a9275ee00834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_tokenizer = spm.SentencePieceProcessor()\n",
    "encoder_tokenizer.load(\"encoder_spm.model\")\n",
    "\n",
    "decoder_tokenizer = spm.SentencePieceProcessor()\n",
    "decoder_tokenizer.load(\"decoder_spm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "382a45a7-2b45-427c-9366-e770727aca0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>korean</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?</td>\n",
       "      <td>much of personal computing is about can you to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...</td>\n",
       "      <td>so a mention a few weeks ago about a rechargea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그러나 이것은 또한 책상도 필요로 하지 않는다 .</td>\n",
       "      <td>like all optical mice , but it also doesn t ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.  달러하는 이 최첨단 무선 광마우스는 허공에서 팔목 , 팔 , 그외에 어떤 부분...</td>\n",
       "      <td>uses gyroscopic sensors to control the cursor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>정보 관리들은 동남 아시아에서의 선박들에 대한 많은  테러  계획들이 실패로 돌아갔...</td>\n",
       "      <td>intelligence officials have revealed a spate o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94095</th>\n",
       "      <td>우리는  월  일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 총...</td>\n",
       "      <td>we are hoping to seize material evidence to pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94096</th>\n",
       "      <td>월요일 술집 종업원  명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했다 .</td>\n",
       "      <td>on monday , police secured statements from six...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94097</th>\n",
       "      <td>그러나 불충분한 증거 확보로 수사에 어려움이 있다 .</td>\n",
       "      <td>but the lack of material evidence is making it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94098</th>\n",
       "      <td>김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다 .</td>\n",
       "      <td>kim and his son both deny the allegations .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94099</th>\n",
       "      <td>경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...</td>\n",
       "      <td>police are planning to seek arrest warrants fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  korean  \\\n",
       "0                    개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?   \n",
       "1      모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...   \n",
       "2                            그러나 이것은 또한 책상도 필요로 하지 않는다 .   \n",
       "3      .  달러하는 이 최첨단 무선 광마우스는 허공에서 팔목 , 팔 , 그외에 어떤 부분...   \n",
       "4      정보 관리들은 동남 아시아에서의 선박들에 대한 많은  테러  계획들이 실패로 돌아갔...   \n",
       "...                                                  ...   \n",
       "94095  우리는  월  일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 총...   \n",
       "94096  월요일 술집 종업원  명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했다 .   \n",
       "94097                      그러나 불충분한 증거 확보로 수사에 어려움이 있다 .   \n",
       "94098                 김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다 .   \n",
       "94099  경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...   \n",
       "\n",
       "                                                 english  \n",
       "0      much of personal computing is about can you to...  \n",
       "1      so a mention a few weeks ago about a rechargea...  \n",
       "2      like all optical mice , but it also doesn t ne...  \n",
       "3      uses gyroscopic sensors to control the cursor ...  \n",
       "4      intelligence officials have revealed a spate o...  \n",
       "...                                                  ...  \n",
       "94095  we are hoping to seize material evidence to pr...  \n",
       "94096  on monday , police secured statements from six...  \n",
       "94097  but the lack of material evidence is making it...  \n",
       "94098        kim and his son both deny the allegations .  \n",
       "94099  police are planning to seek arrest warrants fo...  \n",
       "\n",
       "[94100 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d0205fa-08a8-44a8-8521-848dee13732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그는 민주당 대선후보가 결정 될 때까지 경선을 계속 치르겠다는 뜻을 밝힌 바 있다 .\n",
      "clinton has vowed to stay in the race until someone gets enough delegates to clinch the nomination .\n"
     ]
    }
   ],
   "source": [
    "kor_sample = df[\"korean\"][10000]\n",
    "eng_sample = df[\"english\"][10000]\n",
    "print(kor_sample)\n",
    "print(eng_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97d82ba9-da53-449a-b448-5cd72589fe31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 22,\n",
       " 8,\n",
       " 352,\n",
       " 1380,\n",
       " 13,\n",
       " 318,\n",
       " 190,\n",
       " 1922,\n",
       " 1527,\n",
       " 6,\n",
       " 283,\n",
       " 3596,\n",
       " 2311,\n",
       " 8,\n",
       " 1217,\n",
       " 6,\n",
       " 1690,\n",
       " 116,\n",
       " 26,\n",
       " 5,\n",
       " 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_token = encoder_tokenizer.encode(kor_sample)\n",
    "enc_token = [encoder_tokenizer.bos_id()] + enc_token + [encoder_tokenizer.eos_id()]\n",
    "enc_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fb0d158-d900-43df-97ee-38793aedb923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'그는 민주당 대선후보가 결정 될 때까지 경선을 계속 치르겠다는 뜻을 밝힌 바 있다 .'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_decoding = encoder_tokenizer.decode(enc_token)\n",
    "enc_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aa50c26-2877-4d1b-959a-ac914ddc84e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data, encoder_tokenizer, decoder_tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.encoder_tokenizer = encoder_tokenizer\n",
    "        self.decoder_tokenizer = decoder_tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pad_id = 0\n",
    "        self.bos_id = 1\n",
    "        self.eos_id = 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.data.iloc[idx]['korean']\n",
    "        trg_text = self.data.iloc[idx]['english']\n",
    "\n",
    "        src_ids = self.encoder_tokenizer.encode(src_text)\n",
    "        trg_ids = self.decoder_tokenizer.encode(trg_text)\n",
    "\n",
    "        src_ids = src_ids[:self.max_len]\n",
    "\n",
    "        # Decoder의 입력에는 START_TOKEN과 END_TOKEN을 추가해줍니다. 단, 최대 길이 제한을 적용시킵니다.\n",
    "        trg_input = [self.bos_id] + trg_ids[:self.max_len - 2] + [self.eos_id]\n",
    "        trg_label = trg_ids[:self.max_len - 1] + [self.eos_id]\n",
    "\n",
    "        # 길이가 짧은 경우 PAD_TOKEN을 추가해줍니다.\n",
    "        src_ids = src_ids + [self.pad_id] * (self.max_len - len(src_ids))\n",
    "        trg_input = trg_input + [self.pad_id] * (self.max_len - len(trg_input))\n",
    "        trg_label = trg_label + [self.pad_id] * (self.max_len - len(trg_label))\n",
    "\n",
    "        return torch.tensor(src_ids), torch.tensor(trg_input), torch.tensor(trg_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e096ec1-5e43-4a63-8054-8cb98a19b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8  # 전체 길이의 80%\n",
    "MAX_LEN = 30 # 임의의 값\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_data = df.sample(frac=train_ratio, random_state=42)  # 70% 훈련 데이터\n",
    "valid_data = df.drop(train_data.index)\n",
    "\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "valid_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_data = TranslationDataset(train_data, encoder_tokenizer, decoder_tokenizer, max_len=MAX_LEN)\n",
    "validataion_data = TranslationDataset(valid_data, encoder_tokenizer, decoder_tokenizer, max_len=MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validataion_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24033983-6491-490b-bf78-92683ad15085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30]) torch.Size([64, 30]) torch.Size([64, 30])\n"
     ]
    }
   ],
   "source": [
    "for src, trg_input, trg_label in train_loader:\n",
    "    print(src.shape, trg_input.shape, trg_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f4a3c50-6da5-40f3-a010-ee5dbf10bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: (batch_size, hidden_dim)\n",
    "        # encoder_outputs: (src_len, batch_size, hidden_dim)\n",
    "\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)  # (batch_size, src_len, hidden_dim)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)  # (batch_size, src_len, hidden_dim)\n",
    "\n",
    "        energy = torch.tanh(self.W1(encoder_outputs) + self.W2(hidden))  # (batch_size, src_len, hidden_dim)\n",
    "        attention = self.v(energy).squeeze(2)  # (batch_size, src_len)\n",
    "\n",
    "        return nn.functional.softmax(attention, dim=1)  # (batch_size, src_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "729d5cac-b0a0-418d-99c6-9ba24f5e2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src : (src_len, batch_size)\n",
    "        embedded = self.embedding(src)  # embedded : (src_len, batch_size, emb_dim)\n",
    "        outputs, hidden = self.rnn(embedded)  # outputs : (src_len, batch_size, hidden_dim)\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f6f9140-aa77-4564-94cc-15efbfc2eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, attention):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        # Decoder RNN에는 embedding만 입력\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim)\n",
    "        # 출력층에는 hidden state와 attention value가 결합되어 입력\n",
    "        self.fc_out = nn.Linear(hidden_dim + hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input : (batch_size,)\n",
    "        # hidden : (batch_size, hidden_dim)\n",
    "        # encoder_outputs : (src_len, batch_size, hidden_dim)\n",
    "        input = input.unsqueeze(0)  # input : (1, batch_size)\n",
    "        embedded = self.embedding(input)  # embedded : (1, batch_size, emb_dim)\n",
    "\n",
    "        # attention distribution을 계산합니다. decoder의 이전 hidden state, s_{t-1}와 encoder의 H가 입력됩니다.\n",
    "        a = self.attention(hidden[-1], encoder_outputs)  # a : (batch_size, src_len)\n",
    "\n",
    "        # H에 가중치를 부여해 attention value(Context vector) 계산\n",
    "        a = a.unsqueeze(1)  # a : (batch_size, 1, src_len)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)  # encoder_outputs : (batch_size, src_len, hidden_dim)\n",
    "        context = torch.bmm(a, encoder_outputs)  # context : (batch_size, 1, hidden_dim)\n",
    "        context = context.permute(1, 0, 2)  # context : (1, batch_size, hidden_dim)\n",
    "\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "\n",
    "        # 출력층에서는 현재 hidden state와 context vector를 결합하여 예측값 생성\n",
    "        output = output.squeeze(0)  # output : (batch_size, hidden_dim)\n",
    "        context = context.squeeze(0)  # context : (batch_size, hidden_dim)\n",
    "        prediction = self.fc_out(torch.cat((output, context), dim=1))  # (batch_size, output_dim)\n",
    "\n",
    "        return prediction, hidden, a.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7de120fb-7bd2-4b25-af99-4ee2de6b004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttention(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg=None, max_len=30, bos_id = 1, eos_id=2):\n",
    "        # 학습 모드에서는 trg_len 사용, 추론 모드에서는 max_len까지 동적 생성\n",
    "        batch_size = src.shape[1]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        # 조기 종료를 위해 tensor가 아닌 리스트 사용\n",
    "        outputs = []\n",
    "\n",
    "        # 시각화를 위해 attention 저장\n",
    "        attentions = []\n",
    "\n",
    "        # 인코더를 통해 context 생성\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        if trg is not None:\n",
    "            for t in range(0, trg.shape[0]):\n",
    "                input = trg[t]\n",
    "                output, hidden, attention = self.decoder(input, hidden, encoder_outputs)\n",
    "                outputs.append(output.unsqueeze(0))\n",
    "                attentions.append(attention.unsqueeze(0))\n",
    "\n",
    "        else:\n",
    "\t\t    # inference에서는 target(정답)이 없기 때문에 sos_token을 생성해줍니다.\n",
    "            input = torch.full((batch_size,), bos_id, dtype=torch.long, device=self.device)\n",
    "            finished = torch.zeros(batch_size, dtype=torch.bool, device=self.device)\n",
    "\n",
    "            for t in range(max_len):\n",
    "                output, hidden, attention = self.decoder(input, hidden,  encoder_outputs)\n",
    "                outputs.append(output.unsqueeze(0))\n",
    "                attentions.append(attention.unsqueeze(0))\n",
    "                top1 = output.argmax(1)\n",
    "                input = top1\n",
    "\n",
    "                # 조기 종료 조건\n",
    "                finished |= (top1 == eos_id)\n",
    "                if finished.all():\n",
    "                    break\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=0)  # (trg_len, batch_size, output_dim)\n",
    "        attentions = torch.cat(attentions, dim=0)  # (trg_len, batch_size, src_len)\n",
    "\n",
    "        return outputs, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1be03bd-7270-4843-9d76-0633dbb1b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_dim = len(encoder_tokenizer)\n",
    "output_dim = len(decoder_tokenizer)\n",
    "emb_dim = 256\n",
    "hid_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed25c336-86da-4c04-87f2-000a3f4f6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim, emb_dim, hid_dim).to(device)\n",
    "attention = BahdanauAttention(hid_dim).to(device)\n",
    "decoder = Decoder(output_dim, emb_dim, hid_dim, attention).to(device)\n",
    "model = Seq2SeqAttention(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52f8ed3c-d1cb-4452-99b2-a53897f844c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqAttention(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(8000, 256)\n",
      "    (rnn): GRU(256, 512)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention): BahdanauAttention(\n",
      "      (W1): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (W2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
      "    )\n",
      "    (embedding): Embedding(8000, 256)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (fc_out): Linear(in_features=1024, out_features=8000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c824d1-0da3-4337-840d-871db063b686",
   "metadata": {},
   "source": [
    "## 4. 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d633ccf-2c6f-4fc0-aaf4-486be546f6a8",
   "metadata": {},
   "source": [
    "### (1) Optimizer & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56a41611-ece4-4b51-be56-a68f1cdd0144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c593f5d5-6a59-4f56-8160-05c41618c49d",
   "metadata": {},
   "source": [
    "### (2) train_step 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c1a0ec4-4a79-435e-9a28-2dcc88e9cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "def train_step(model, data_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch+1}\", leave=True)\n",
    "\n",
    "    for src, trg_input, trg_label in progress_bar:\n",
    "        src, trg_input, trg_label = src.to(device), trg_input.to(device), trg_label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs,_ = model(src, trg_input)\n",
    "\n",
    "        # (trg_len, batch_size, output_dim)을 (batch_size * trg_len, output_dim)으로 변환\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])\n",
    "        trg_label = trg_label.view(-1)\n",
    "\n",
    "        loss = criterion(outputs, trg_label)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "print(\"슝~\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a4921-b35f-4bb9-be85-ac2d348b174e",
   "metadata": {},
   "source": [
    "### (3) 훈련 시작하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af067151-c687-42dd-a919-3975b5fb3e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1177/1177 [04:45<00:00,  4.12it/s, loss=4.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 4.7719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1177/1177 [04:45<00:00,  4.13it/s, loss=5.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 4.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:  74%|███████▎  | 866/1177 [03:30<01:15,  4.13it/s, loss=4.62]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 6: 100%|██████████| 1177/1177 [04:45<00:00,  4.12it/s, loss=4.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 4.4736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1177/1177 [04:45<00:00,  4.12it/s, loss=4.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 4.4440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:  26%|██▌       | 303/1177 [01:13<03:31,  4.14it/s, loss=4.27]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 9: 100%|██████████| 1177/1177 [04:45<00:00,  4.12it/s, loss=4.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 4.3974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1177/1177 [04:45<00:00,  4.12it/s, loss=4.54]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 4.3794\n",
      "CPU times: user 44min 16s, sys: 3min 25s, total: 47min 41s\n",
      "Wall time: 47min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_step(model, train_loader, optimizer, criterion, epoch)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Train Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be2a3482-06f5-43a6-8d91-3acada52e222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "def eval_step(model, data_loader, optimizer, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    for src, trg_input, trg_label in data_loader:\n",
    "        src, trg_input, trg_label = src.to(device), trg_input.to(device), trg_label.to(device)\n",
    "\n",
    "        outputs, _ = model(src, trg_input)\n",
    "\n",
    "        # (trg_len, batch_size, output_dim)을 (batch_size * trg_len, output_dim)으로 변환\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])\n",
    "        trg_label = trg_label.view(-1)\n",
    "\n",
    "        loss = criterion(outputs, trg_label)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08236305-552c-4dbe-a268-7da333edf96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1177/1177 [04:45<00:00,  4.12it/s, loss=4.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 4.3623, Validation Loss: 4.7544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  27%|██▋       | 321/1177 [01:18<03:27,  4.12it/s, loss=4.26]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 3: 100%|██████████| 1177/1177 [04:46<00:00,  4.11it/s, loss=4.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 4.3331, Validation Loss: 4.7671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1177/1177 [04:46<00:00,  4.11it/s, loss=4.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 4.3208, Validation Loss: 4.7674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:  27%|██▋       | 319/1177 [01:17<03:29,  4.10it/s, loss=4.35]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_step(model, train_loader, optimizer, criterion, epoch)\n",
    "    valid_loss = eval_step(model, validation_loader, optimizer, criterion)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41e2ab-c1e2-442b-9edd-e675fb9e1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, model, encoder_tokenizer, decoder_tokenizer, max_len=30):\n",
    "    model.eval()\n",
    "\n",
    "    sentence = preprocess_korean(sentence)\n",
    "    src_ids = encoder_tokenizer.encode(sentence)\n",
    "    src_ids = src_ids[:max_len]\n",
    "    src_ids = src_ids + [0] * (max_len - len(src_ids))  # 패딩 추가\n",
    "    src_tensor = torch.tensor(src_ids).unsqueeze(1).to(device)  # (src_len, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs, attentions = model(src_tensor, max_len=max_len)\n",
    "\n",
    "    result = [decoder_tokenizer.decode([token.item()]) for token in outputs.argmax(2).squeeze(1)]\n",
    "\n",
    "    if \"<end>\" in result:\n",
    "        result = result[:result.index(\"<end>\")]\n",
    "\n",
    "    return result, sentence, attentions.squeeze(1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706ff9c-f63c-4d94-b757-5317ea89107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticks(range(len(sentence)))\n",
    "    ax.set_xticklabels(sentence, fontdict=fontdict, rotation=90)\n",
    "\n",
    "    ax.set_yticks(range(len(predicted_sentence)))\n",
    "    ax.set_yticklabels(predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efce230-2106-420a-8271-9e60fdd17f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, model, encoder_tokenizer, decoder_tokenizer, max_len=30):\n",
    "    result, sentence, attention = evaluate(sentence, model, encoder_tokenizer, decoder_tokenizer, max_len)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    # Attention 크기 조정 (trg_len, src_len)\n",
    "    attention = attention[:len(result), :len(sentence.split())]\n",
    "\n",
    "    plot_attention(attention, sentence.split(), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d899f-8cf7-472e-aa9f-ff37086ef280",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"가장 쌘놈이 모든걸 가진다.\", model, encoder_tokenizer, decoder_tokenizer, max_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff5135-dae2-437a-9571-60fa1e80d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"도와 드릴까요?\", model, encoder_tokenizer, decoder_tokenizer, max_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1c2e9-d890-44fa-8a07-41aa7a9afff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 예제\n",
    "translate(\"커피 한잔 마실 수 있을까요?\", model, encoder_tokenizer, decoder_tokenizer, max_len=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
