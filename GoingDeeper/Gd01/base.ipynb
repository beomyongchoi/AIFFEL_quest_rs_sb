{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "448cac5b-2a5d-4caa-82b5-83d5e2ce184e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# $ sudo apt update\n",
    "# $ sudo apt install default-jre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2986381-7be3-47ac-9a29-a835d2234476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install konlpy\n",
    "# ! cd ~/work/text_preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6c3a09-332b-41d1-9a85-2259fd1a7ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "# %cd Mecab-ko-for-Google-Colab\n",
    "# ! bash install_mecab-ko_on_colab190912.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b5d6f5-d306-404c-92da-edf6e39742d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d701d6-a55a-496f-b480-b0af397f7a73",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['자연어', '처리', '가', '너무', '재밌', '어서', '밥', '먹', '는', '것', '도', '가끔', '까먹', '어요']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "print(mecab.morphs('자연어처리가너무재밌어서밥먹는것도가끔까먹어요'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "059bc2f9-0b0a-44b9-88b5-2b7373baf325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hannanum] \n",
      "[('코로나바이러스', 'N'), ('는', 'J'), ('2019년', 'N'), ('12월', 'N'), ('중국', 'N'), ('우한', 'N'), ('에서', 'J'), ('처음', 'M'), ('발생', 'N'), ('하', 'X'), ('ㄴ', 'E'), ('뒤', 'N'), ('전', 'N'), ('세계', 'N'), ('로', 'J'), ('확산', 'N'), ('되', 'X'), ('ㄴ', 'E'), (',', 'S'), ('새롭', 'P'), ('은', 'E'), ('유형', 'N'), ('의', 'J'), ('호흡기', 'N'), ('감염', 'N'), ('질환', 'N'), ('이', 'J'), ('ㅂ니다', 'E'), ('.', 'S')]\n",
      "[Kkma] \n",
      "[('코로나', 'NNG'), ('바', 'NNG'), ('이러', 'MAG'), ('슬', 'VV'), ('는', 'ETD'), ('2019', 'NR'), ('년', 'NNM'), ('12', 'NR'), ('월', 'NNM'), ('중국', 'NNG'), ('우', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('에', 'VV'), ('서', 'ECD'), ('처음', 'NNG'), ('발생', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('뒤', 'NNG'), ('전', 'NNG'), ('세계', 'NNG'), ('로', 'JKM'), ('확산', 'NNG'), ('되', 'XSV'), ('ㄴ', 'ETD'), (',', 'SP'), ('새', 'NNG'), ('롭', 'XSA'), ('ㄴ', 'ETD'), ('유형', 'NNG'), ('의', 'JKG'), ('호흡기', 'NNG'), ('감염', 'NNG'), ('질환', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EFN'), ('.', 'SF')]\n",
      "[Komoran] \n",
      "[('코로나바이러스', 'NNP'), ('는', 'JX'), ('2019', 'SN'), ('년', 'NNB'), ('12월', 'NNP'), ('중국', 'NNP'), ('우', 'NNP'), ('한', 'NNP'), ('에서', 'JKB'), ('처음', 'NNG'), ('발생', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETM'), ('뒤', 'NNG'), ('전', 'MM'), ('세계로', 'NNP'), ('확산', 'NNG'), ('되', 'XSV'), ('ㄴ', 'ETM'), (',', 'SP'), ('새롭', 'VA'), ('ㄴ', 'ETM'), ('유형', 'NNP'), ('의', 'JKG'), ('호흡기', 'NNG'), ('감염', 'NNP'), ('질환', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EF'), ('.', 'SF')]\n",
      "[Mecab] \n",
      "[('코로나', 'NNP'), ('바이러스', 'NNG'), ('는', 'JX'), ('2019', 'SN'), ('년', 'NNBC'), ('12', 'SN'), ('월', 'NNBC'), ('중국', 'NNP'), ('우한', 'NNP'), ('에서', 'JKB'), ('처음', 'NNG'), ('발생', 'NNG'), ('한', 'XSV+ETM'), ('뒤', 'NNG'), ('전', 'NNG'), ('세계', 'NNG'), ('로', 'JKB'), ('확산', 'NNG'), ('된', 'XSV+ETM'), (',', 'SC'), ('새로운', 'VA+ETM'), ('유형', 'NNG'), ('의', 'JKG'), ('호흡기', 'NNG'), ('감염', 'NNG'), ('질환', 'NNG'), ('입니다', 'VCP+EF'), ('.', 'SF')]\n",
      "[Okt] \n",
      "[('코로나바이러스', 'Noun'), ('는', 'Josa'), ('2019년', 'Number'), ('12월', 'Number'), ('중국', 'Noun'), ('우한', 'Noun'), ('에서', 'Josa'), ('처음', 'Noun'), ('발생', 'Noun'), ('한', 'Josa'), ('뒤', 'Noun'), ('전', 'Noun'), ('세계', 'Noun'), ('로', 'Josa'), ('확산', 'Noun'), ('된', 'Verb'), (',', 'Punctuation'), ('새로운', 'Adjective'), ('유형', 'Noun'), ('의', 'Josa'), ('호흡기', 'Noun'), ('감염', 'Noun'), ('질환', 'Noun'), ('입니다', 'Adjective'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "# 1. 사용할 모든 형태소 분석기를 import 합니다. (이 부분이 누락되었습니다)\n",
    "from konlpy.tag import Hannanum, Kkma, Komoran, Mecab, Okt\n",
    "\n",
    "# 2. 토크나이저 리스트를 생성하고 실행합니다.\n",
    "tokenizer_list = [Hannanum(), Kkma(), Komoran(), Mecab(), Okt()]\n",
    "\n",
    "kor_text = '코로나바이러스는 2019년 12월 중국 우한에서 처음 발생한 뒤 전 세계로 확산된, 새로운 유형의 호흡기 감염 질환입니다.'\n",
    "\n",
    "for tokenizer in tokenizer_list:\n",
    "    print('[{}] \\n{}'.format(tokenizer.__class__.__name__, tokenizer.pos(kor_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1e4aeff-fa00-4271-a8ae-4fa97eac1173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.11\n"
     ]
    }
   ],
   "source": [
    "# python 버전 확인\n",
    "\n",
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e369f7af-f6c7-4b11-a44b-c716c27452a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==4.3.2 in /opt/conda/lib/python3.12/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.12/site-packages (from gensim==4.3.2) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from gensim==4.3.2) (1.12.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /opt/conda/lib/python3.12/site-packages (from gensim==4.3.2) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.12/site-packages (from smart_open>=1.8.1->gensim==4.3.2) (1.17.3)\n"
     ]
    }
   ],
   "source": [
    "# 유사단어 찾기를 위한 gensim 설치\n",
    "\n",
    "!pip install gensim==4.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44b47b0c-b627-4e59-8115-60effcb2bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy==1.12.0 in /opt/conda/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy==1.26.3 in /opt/conda/lib/python3.12/site-packages (1.26.3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 의존성 연결을 위해 다운그레이드를 진행\n",
    "\n",
    "!pip install scipy==1.12.0 numpy==1.26.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49adf9c5-30e7-4750-8442-0a6a2ca192d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "0.6.0\n",
      "4.3.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 설치 라이브러리 버전 확인\n",
    "\n",
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "565a6102-3b0e-4f10-abc3-4f4bee258d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.12/site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.12/site-packages (from wordcloud) (1.26.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (from wordcloud) (11.2.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (from wordcloud) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->wordcloud) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->wordcloud) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->wordcloud) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->wordcloud) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0813348-8c3a-4da3-bfaa-cd6e72a114d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Note, selecting 'fonts-nanum-extra' for glob 'fonts-nanum*'\n",
      "Note, selecting 'fonts-nanum-coding' for glob 'fonts-nanum*'\n",
      "Note, selecting 'fonts-nanum-eco' for glob 'fonts-nanum*'\n",
      "Note, selecting 'fonts-nanum' for glob 'fonts-nanum*'\n",
      "fonts-nanum is already the newest version (20200506-1).\n",
      "fonts-nanum-coding is already the newest version (2.5-3).\n",
      "fonts-nanum-eco is already the newest version (1.000-7).\n",
      "fonts-nanum-extra is already the newest version (20200506-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
      "Font directories:\n",
      "\t/root/.local/share/fonts\n",
      "\t/usr/local/share/fonts\n",
      "\t/usr/share/fonts\n",
      "\t/root/.fonts\n",
      "\t/usr/share/texmf/fonts/opentype/public/lm\n",
      "\t/usr/share/texmf/fonts/opentype/public/lm-math\n",
      "\t/usr/share/fonts/X11\n",
      "\t/usr/share/fonts/cMap\n",
      "\t/usr/share/fonts/cmap\n",
      "\t/usr/share/fonts/opentype\n",
      "\t/usr/share/fonts/truetype\n",
      "\t/usr/share/fonts/type1\n",
      "\t/usr/share/fonts/X11/Type1\n",
      "\t/usr/share/fonts/X11/encodings\n",
      "\t/usr/share/fonts/X11/util\n",
      "\t/usr/share/fonts/cmap/adobe-cns1\n",
      "\t/usr/share/fonts/cmap/adobe-gb1\n",
      "\t/usr/share/fonts/cmap/adobe-japan1\n",
      "\t/usr/share/fonts/cmap/adobe-japan2\n",
      "\t/usr/share/fonts/cmap/adobe-korea1\n",
      "\t/usr/share/fonts/opentype/urw-base35\n",
      "\t/usr/share/fonts/truetype/dejavu\n",
      "\t/usr/share/fonts/truetype/liberation\n",
      "\t/usr/share/fonts/truetype/nanum\n",
      "\t/usr/share/fonts/type1/texlive-fonts-recommended\n",
      "\t/usr/share/fonts/type1/urw-base35\n",
      "\t/usr/share/fonts/X11/encodings/large\n",
      "/root/.local/share/fonts: skipping, no such directory\n",
      "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
      "/usr/share/fonts: caching, new cache contents: 0 fonts, 6 dirs\n",
      "/usr/share/fonts/X11: caching, new cache contents: 0 fonts, 3 dirs\n",
      "/usr/share/fonts/X11/Type1: caching, new cache contents: 35 fonts, 0 dirs\n",
      "/usr/share/fonts/X11/encodings: caching, new cache contents: 0 fonts, 1 dirs\n",
      "/usr/share/fonts/X11/encodings/large: caching, new cache contents: 0 fonts, 0 dirs\n",
      "/usr/share/fonts/X11/util: caching, new cache contents: 0 fonts, 0 dirs\n",
      "/usr/share/fonts/cMap: caching, new cache contents: 0 fonts, 0 dirs\n",
      "/usr/share/fonts/cmap: caching, new cache contents: 0 fonts, 5 dirs\n",
      "/usr/share/fonts/cmap/adobe-cns1: caching, new cache contents: 0 fonts, 0 dirs\n",
      "/usr/share/fonts/cmap/adobe-gb1: caching, new cache contents: 0 fonts, 0 dirs\n",
      "/usr/share/fonts/cmap/adobe-japan1: caching, new cache contents: 0 fonts, 0 dirs\n",
      "/usr/share/fonts/cmap/adobe-japan2: caching, new cache contents: 0 fonts, 0 dirs\n",
      "/usr/share/fonts/cmap/adobe-korea1: caching, new cache contents: 0 fonts, 0 dirs\n",
      "/usr/share/fonts/opentype: caching, new cache contents: 0 fonts, 1 dirs\n",
      "/usr/share/fonts/opentype/urw-base35: caching, new cache contents: 35 fonts, 0 dirs\n",
      "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
      "/usr/share/fonts/truetype/dejavu: caching, new cache contents: 22 fonts, 0 dirs\n",
      "/usr/share/fonts/truetype/liberation: caching, new cache contents: 12 fonts, 0 dirs\n",
      "/usr/share/fonts/truetype/nanum: caching, new cache contents: 39 fonts, 0 dirs\n",
      "/usr/share/fonts/type1: caching, new cache contents: 0 fonts, 2 dirs\n",
      "/usr/share/fonts/type1/texlive-fonts-recommended: caching, new cache contents: 12 fonts, 0 dirs\n",
      "/usr/share/fonts/type1/urw-base35: caching, new cache contents: 35 fonts, 0 dirs\n",
      "/root/.fonts: skipping, no such directory\n",
      "/usr/share/texmf/fonts/opentype/public/lm: caching, new cache contents: 72 fonts, 0 dirs\n",
      "/usr/share/texmf/fonts/opentype/public/lm-math: caching, new cache contents: 1 fonts, 0 dirs\n",
      "/usr/share/fonts/X11: skipping, looped directory detected\n",
      "/usr/share/fonts/cMap: skipping, looped directory detected\n",
      "/usr/share/fonts/cmap: skipping, looped directory detected\n",
      "/usr/share/fonts/opentype: skipping, looped directory detected\n",
      "/usr/share/fonts/truetype: skipping, looped directory detected\n",
      "/usr/share/fonts/type1: skipping, looped directory detected\n",
      "/usr/share/fonts/X11/Type1: skipping, looped directory detected\n",
      "/usr/share/fonts/X11/encodings: skipping, looped directory detected\n",
      "/usr/share/fonts/X11/util: skipping, looped directory detected\n",
      "/usr/share/fonts/cmap/adobe-cns1: skipping, looped directory detected\n",
      "/usr/share/fonts/cmap/adobe-gb1: skipping, looped directory detected\n",
      "/usr/share/fonts/cmap/adobe-japan1: skipping, looped directory detected\n",
      "/usr/share/fonts/cmap/adobe-japan2: skipping, looped directory detected\n",
      "/usr/share/fonts/cmap/adobe-korea1: skipping, looped directory detected\n",
      "/usr/share/fonts/opentype/urw-base35: skipping, looped directory detected\n",
      "/usr/share/fonts/truetype/dejavu: skipping, looped directory detected\n",
      "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
      "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
      "/usr/share/fonts/type1/texlive-fonts-recommended: skipping, looped directory detected\n",
      "/usr/share/fonts/type1/urw-base35: skipping, looped directory detected\n",
      "/usr/share/fonts/X11/encodings/large: skipping, looped directory detected\n",
      "/var/cache/fontconfig: cleaning cache directory\n",
      "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
      "/root/.fontconfig: not cleaning non-existent cache directory\n",
      "fc-cache: succeeded\n"
     ]
    }
   ],
   "source": [
    "# 1. 나눔폰트 설치\n",
    "!sudo apt-get -y install fonts-nanum*\n",
    "\n",
    "# 2. 폰트 캐시 재생성\n",
    "!sudo fc-cache -fv\n",
    "\n",
    "# 3. matplotlib 캐시 삭제\n",
    "!rm ~/.cache/matplotlib -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e38d3fb4-76be-4469-906c-07dadc523b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2f32efa-b036-48a7-9b40-63caae6af53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.12/site-packages (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "# 1. SentencePiece 라이브러리 설치\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "759d0bfa-1964-4247-8973-1ea9f69eeef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터 로드 및 전처리 완료\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================================\n",
    "# 1. 라이브러리 Import\n",
    "# ====================================================================================\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- 비교 실험을 위한 토크나이저 ---\n",
    "import sentencepiece as spm\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# ====================================================================================\n",
    "# 2. 중앙 설정 (Configuration)\n",
    "# ====================================================================================\n",
    "CFG = {\n",
    "    # --- 실험 선택 ---\n",
    "    'TOKENIZER_TYPE': 'KoNLPy', # 'SentencePiece' 또는 'KoNLPy' 선택\n",
    "    'KONLPY_TOKENIZER': 'Mecab',     # TOKENIZER_TYPE이 'KoNLPy'일 경우, 사용할 형태소 분석기\n",
    "    \n",
    "    # --- SentencePiece 하이퍼파라미터 ---\n",
    "    'SP_VOCAB_SIZE': 10000,          # SentencePiece 단어 집합 크기\n",
    "    'SP_MODEL_TYPE': 'bpe',          # 'bpe' 또는 'unigram'\n",
    "    \n",
    "    # --- KoNLPy 하이퍼파라미터 (추가) ---\n",
    "    'KONLPY_VOCAB_SIZE': 10000,      # KoNLPy 사용 시 단어 집합 크기 제한\n",
    "    \n",
    "    # --- 모델 하이퍼파라미터 ---\n",
    "    'EMBEDDING_DIM': 128,\n",
    "    'HIDDEN_DIM': 128,\n",
    "    'N_LAYERS': 1,\n",
    "    'DROPOUT': 0.6,\n",
    "    \n",
    "    # --- 학습 하이퍼파라미터 ---\n",
    "    'EPOCHS': 20,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'BATCH_SIZE': 128,\n",
    "    'MAX_LEN': 40,                   # 문장 최대 길이\n",
    "    'PATIENCE': 3,                   # 조기 종료 조건\n",
    "    'WEIGHT_DECAY': 1e-5,            # 가중치 감쇠 (L2 규제)\n",
    "    \n",
    "    # --- 기타 설정 ---\n",
    "    'SEED': 42,\n",
    "    'DEVICE': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'MODEL_SAVE_PATH': 'best_model.pth',\n",
    "}\n",
    "\n",
    "# ====================================================================================\n",
    "# 3. 유틸리티 함수\n",
    "# ====================================================================================\n",
    "def seed_everything(seed):\n",
    "    \"\"\"재현성을 위한 시드 고정 함수\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ====================================================================================\n",
    "# 4. 데이터 준비 함수\n",
    "# ====================================================================================\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"NSMC 데이터를 로드하고 전처리하는 함수\"\"\"\n",
    "    # data_path = os.path.join(os.getenv(\"HOME\"), 'work', 'workplace', 'AIFFEL_quest_rs', 'Exploration', 'Ex05', 'sentiment_classification', 'data')\n",
    "    data_path = os.path.join(os.getenv(\"HOME\"), 'work', 'mecab2', 'data')\n",
    "    train_data = pd.read_table(os.path.join(data_path, 'ratings_train.txt'))\n",
    "    test_data = pd.read_table(os.path.join(data_path, 'ratings_test.txt'))\n",
    "    \n",
    "    # --- 훈련 데이터 정제 ---\n",
    "    train_data.dropna(subset=['document'], inplace=True)\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    \n",
    "    # --- 테스트 데이터 정제 ---\n",
    "    test_data.dropna(subset=['document'], inplace=True)\n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    \n",
    "    # --- 데이터셋 분리 ---\n",
    "    train_set, val_set = train_test_split(train_data, test_size=0.2, random_state=CFG['SEED'], stratify=train_data['label'])\n",
    "    \n",
    "    print(\"✅ 데이터 로드 및 전처리 완료\")\n",
    "    return train_set, val_set, test_data\n",
    "\n",
    "# ====================================================================================\n",
    "# 5. 토크나이저 생성 함수 (KoNLPy 로직 수정)\n",
    "# ====================================================================================\n",
    "def get_tokenizer(cfg, train_df):\n",
    "    \"\"\"CFG에 따라 SentencePiece 또는 KoNLPy 토크나이저와 vocab_size를 반환\"\"\"\n",
    "    \n",
    "    if cfg['TOKENIZER_TYPE'] == 'SentencePiece':\n",
    "        # --- (SentencePiece 로직은 이전과 동일) ---\n",
    "        corpus_path = 'nsmc_corpus.txt'\n",
    "        model_prefix = f'nsmc_{cfg[\"SP_MODEL_TYPE\"]}_{cfg[\"SP_VOCAB_SIZE\"]}'\n",
    "        train_df['document'].to_csv(corpus_path, index=False, header=False)\n",
    "        spm.SentencePieceTrainer.train(\n",
    "            f'--input={corpus_path} --model_prefix={model_prefix} '\n",
    "            f'--vocab_size={cfg[\"SP_VOCAB_SIZE\"]} --model_type={cfg[\"SP_MODEL_TYPE\"]}'\n",
    "        )\n",
    "        processor = spm.SentencePieceProcessor()\n",
    "        processor.load(f'{model_prefix}.model')\n",
    "        vocab_size = processor.get_piece_size()\n",
    "\n",
    "        def tokenize_fn(corpus, max_len):\n",
    "            sequences = []\n",
    "            for sentence in corpus:\n",
    "                ids = processor.encode_as_ids(str(sentence))\n",
    "                ids = ids[:max_len] if len(ids) > max_len else ids + [0] * (max_len - len(ids))\n",
    "                sequences.append(ids)\n",
    "            return torch.tensor(sequences, dtype=torch.long)\n",
    "            \n",
    "        print(f\"✅ SentencePiece 토크나이저 준비 완료 (vocab_size: {vocab_size})\")\n",
    "        return tokenize_fn, vocab_size\n",
    "\n",
    "    elif cfg['TOKENIZER_TYPE'] == 'KoNLPy':\n",
    "        # --- KoNLPy 토크나이저 생성 (vocab_size 제한 로직 추가) ---\n",
    "        if cfg['KONLPY_TOKENIZER'] == 'Mecab':\n",
    "            tokenizer = Mecab()\n",
    "        else:\n",
    "            from konlpy.tag import Okt\n",
    "            tokenizer = Okt()\n",
    "            \n",
    "        # 1. 단어 빈도수 계산\n",
    "        word_counts = {}\n",
    "        for sentence in tqdm(train_df['document'], desc=\"KoNLPy Freq. Counting\"):\n",
    "            tokens = tokenizer.morphs(str(sentence))\n",
    "            for token in tokens:\n",
    "                word_counts[token] = word_counts.get(token, 0) + 1\n",
    "        \n",
    "        # 2. 빈도수 기준으로 상위 단어 선택\n",
    "        # <PAD>, <UNK> 토큰을 위해 (vocab_size - 2)개만 선택\n",
    "        sorted_words = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "        top_words = sorted_words[:cfg['KONLPY_VOCAB_SIZE'] - 2]\n",
    "        \n",
    "        # 3. 최종 단어 사전 구축\n",
    "        word_index = {'<PAD>': 0, '<UNK>': 1}\n",
    "        for word in top_words:\n",
    "            word_index[word] = len(word_index)\n",
    "            \n",
    "        vocab_size = len(word_index)\n",
    "\n",
    "        def tokenize_fn(corpus, max_len):\n",
    "            sequences = []\n",
    "            for sentence in corpus:\n",
    "                tokens = tokenizer.morphs(str(sentence))\n",
    "                ids = [word_index.get(token, 1) for token in tokens] # 사전에 없으면 <UNK> (1)\n",
    "                ids = ids[:max_len] if len(ids) > max_len else ids + [0] * (max_len - len(ids))\n",
    "                sequences.append(ids)\n",
    "            return torch.tensor(sequences, dtype=torch.long)\n",
    "            \n",
    "        print(f\"✅ KoNLPy({cfg['KONLPY_TOKENIZER']}) 토크나이저 준비 완료 (vocab_size: {vocab_size})\")\n",
    "        return tokenize_fn, vocab_size\n",
    "\n",
    "# ====================================================================================\n",
    "# 6. 모델 정의\n",
    "# ====================================================================================\n",
    "class SentimentGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super(SentimentGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        gru_out, hidden = self.gru(embedded)\n",
    "        last_output = gru_out[:, -1, :]\n",
    "        last_output = self.dropout(last_output)\n",
    "        output = self.fc(last_output)\n",
    "        return output\n",
    "\n",
    "# ====================================================================================\n",
    "# 7. 학습 및 평가 함수 (출력값 수정)\n",
    "# ====================================================================================\n",
    "def run_experiment(cfg, train_set, val_set, test_set):\n",
    "    \"\"\"하나의 설정(CFG)으로 전체 실험을 실행하는 메인 함수\"\"\"\n",
    "    \n",
    "    # --- 1. 토크나이저 및 데이터로더 준비 ---\n",
    "    tokenize_fn, vocab_size = get_tokenizer(cfg, train_set)\n",
    "    \n",
    "    X_train = tokenize_fn(train_set['document'].tolist(), cfg['MAX_LEN'])\n",
    "    y_train = torch.tensor(train_set['label'].values, dtype=torch.float32)\n",
    "    X_val = tokenize_fn(val_set['document'].tolist(), cfg['MAX_LEN'])\n",
    "    y_val = torch.tensor(val_set['label'].values, dtype=torch.float32)\n",
    "    X_test = tokenize_fn(test_set['document'].tolist(), cfg['MAX_LEN'])\n",
    "    y_test = torch.tensor(test_set['label'].values, dtype=torch.float32)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=cfg['BATCH_SIZE'], shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=cfg['BATCH_SIZE'], shuffle=False)\n",
    "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=cfg['BATCH_SIZE'], shuffle=False)\n",
    "    \n",
    "    # --- 2. 모델, 손실함수, 옵티마이저 정의 ---\n",
    "    model = SentimentGRU(vocab_size, cfg['EMBEDDING_DIM'], cfg['HIDDEN_DIM'], cfg['N_LAYERS'], cfg['DROPOUT']).to(cfg['DEVICE'])\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg['LEARNING_RATE'], weight_decay=cfg['WEIGHT_DECAY'])\n",
    "    \n",
    "    # --- 3. 학습 및 조기 종료 ---\n",
    "    patience_counter = 0\n",
    "    best_loss = np.Inf\n",
    "    \n",
    "    print(\"\\n🚀 모델 학습을 시작합니다...\")\n",
    "    for epoch in range(cfg['EPOCHS']):\n",
    "        # --- 훈련 단계 ---\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0, 0, 0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1:02d} [Train]\"):\n",
    "            inputs, labels = inputs.to(cfg['DEVICE']), labels.to(cfg['DEVICE'])\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs.squeeze()) > 0.5\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "        # <<<--- 훈련 결과 계산 --- START ---\n",
    "        # 매 에포크의 훈련이 끝나면 평균 손실과 정확도를 계산합니다.\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "        # <<<--- 훈련 결과 계산 --- END ---\n",
    "        \n",
    "        # --- 검증 단계 ---\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(cfg['DEVICE']), labels.to(cfg['DEVICE'])\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs.squeeze(), labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.sigmoid(outputs.squeeze()) > 0.5\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        # <<<--- 출력문 수정 --- START ---\n",
    "        # 기존 출력문에 avg_train_loss와 train_accuracy를 추가합니다.\n",
    "        print(f\"Epoch {epoch+1:02d} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy*100:.2f}% | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy*100:.2f}%\")\n",
    "        # <<<--- 출력문 수정 --- END ---\n",
    "        \n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), cfg['MODEL_SAVE_PATH'])\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= cfg['PATIENCE']:\n",
    "            print(f\"🛑 Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "            \n",
    "    # --- 4. 최종 평가 ---\n",
    "    print(f\"\\n🧪 최고 성능 모델('{cfg['MODEL_SAVE_PATH']}')로 최종 평가를 시작합니다...\")\n",
    "    model.load_state_dict(torch.load(cfg['MODEL_SAVE_PATH']))\n",
    "    model.eval()\n",
    "    test_loss, test_correct, test_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"[Testing]\"):\n",
    "            inputs, labels = inputs.to(cfg['DEVICE']), labels.to(cfg['DEVICE'])\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs.squeeze(), labels)\n",
    "            test_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs.squeeze()) > 0.5\n",
    "            test_correct += (preds == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = test_correct / test_total\n",
    "    \n",
    "    print(\"\\n🎉 모델 평가가 완료되었습니다.\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  - 최종 테스트 손실 (Loss): {avg_test_loss:.4f}\")\n",
    "    print(f\"  - 최종 테스트 정확도 (Accuracy): {test_accuracy*100:.2f}%\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    return {'loss': avg_test_loss, 'accuracy': test_accuracy}\n",
    "\n",
    "# ====================================================================================\n",
    "# 8. 메인 실행 블록\n",
    "# ====================================================================================\n",
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['SEED'])\n",
    "    train_set, val_set, test_set = load_and_preprocess_data()\n",
    "    \n",
    "    # --- 여기서부터 실험을 실행합니다 ---\n",
    "    # 예시 1: SentencePiece (bpe, vocab_size=10000) 실험\n",
    "    CFG['TOKENIZER_TYPE'] = 'SentencePiece'\n",
    "    CFG['SP_MODEL_TYPE'] = 'bpm'\n",
    "    # results = run_experiment(CFG, train_set, val_set, test_set)\n",
    "    \n",
    "    # 예시 2: KoNLPy (Mecab) 실험 (CFG 변경 후 실행)\n",
    "    # CFG['TOKENIZER_TYPE'] = 'KoNLPy'\n",
    "    # CFG['KONLPY_TOKENIZER'] = 'Mecab'\n",
    "    # results_mecab = run_experiment(CFG, train_set, val_set, test_set)\n",
    "    \n",
    "    # 예시 3: SentencePiece (unigram, vocab_size=16000) 실험 (CFG 변경 후 실행)\n",
    "    # CFG['TOKENIZER_TYPE'] = 'SentencePiece'\n",
    "    # CFG['SP_MODEL_TYPE'] = 'unigram'\n",
    "    # CFG['SP_VOCAB_SIZE'] = 16000\n",
    "    # results_sp_uni = run_experiment(CFG, train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f049d997-a422-4a37-bf7e-e71c933cc7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1233c30c-742d-4bf3-89fa-b71616dffd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66e86faf-dbed-4d9b-928b-ae111b8452ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터(네이버 영화 리뷰)) 준비 및 확인\n",
    "\n",
    "#운영 체제 독립성과 가독성 및 유지 보수 편의성을 위한 코드 개선 \n",
    "# data_path = os.path.join(os.getenv(\"HOME\"), 'work', 'workplace', 'AIFFEL_quest_rs', 'Exploration', 'Ex05', 'sentiment_classification', 'data')\n",
    "data_path = os.path.join(os.getenv(\"HOME\"), 'work', 'mecab2', 'data')\n",
    "train_data = pd.read_table(os.path.join(data_path, 'ratings_train.txt'))\n",
    "test_data = pd.read_table(os.path.join(data_path, 'ratings_test.txt'))\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3143d6bc-32df-46d0-89d4-08dc9f499a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 제거 전: 150000\n",
      "결측치 제거 후: 149995\n",
      "중복 데이터 제거 전: 149995\n",
      "중복 데이터 제거 후: 146182\n"
     ]
    }
   ],
   "source": [
    "#====================================================================================\n",
    "# 1-2. 데이터 전처리 (정제)\n",
    "#====================================================================================\n",
    "# 1) 결측치 제거\n",
    "# 'document' 컬럼에 결측치(NaN)가 있는 행을 제거합니다.\n",
    "print(\"결측치 제거 전:\", len(train_data))\n",
    "train_data.dropna(subset=['document'], inplace=True)\n",
    "print(\"결측치 제거 후:\", len(train_data))\n",
    "\n",
    "# 2) 중복 데이터 제거\n",
    "# 'document' 컬럼 기준으로 중복된 리뷰를 제거합니다.\n",
    "print(\"중복 데이터 제거 전:\", len(train_data))\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "print(\"중복 데이터 제거 후:\", len(train_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b84a3a1b-6bb1-4705-b2fb-9618b2d8c169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 개수: 116945\n",
      "검증 데이터셋 개수: 29237\n",
      "테스트 데이터셋 개수: 50000\n"
     ]
    }
   ],
   "source": [
    "#====================================================================================\n",
    "# 1-3. 데이터셋 분리\n",
    "#====================================================================================\n",
    "# 훈련 데이터셋을 훈련(train)과 검증(validation) 데이터셋으로 분리합니다.\n",
    "# 테스트 데이터는 이미 분리되어 있으므로, 훈련 데이터를 8:2 비율로 나눕니다.\n",
    "# stratify=train_data['label'] 옵션은 원본 데이터의 긍정/부정 비율을 유지하며 분리하도록 합니다.\n",
    "train_set, val_set = train_test_split(train_data, test_size=0.2, random_state=42, stratify=train_data['label'])\n",
    "\n",
    "print(\"훈련 데이터셋 개수:\", len(train_set))\n",
    "print(\"검증 데이터셋 개수:\", len(val_set))\n",
    "print(\"테스트 데이터셋 개수:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63f3dd32-cd5a-4671-992a-a16f862468e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'nsmc_corpus.txt' 파일이 성공적으로 저장되었습니다.\n",
      "\n",
      "[생성된 파일 내용 (상위 5줄)]\n",
      "허니잼 예스잼 꿀잼 잼잼\n",
      ".. 딱이 할말이 없다.\n",
      "흥행이 안되는 이유가 있음. 엄청난 졸작이다.\n",
      "재밌는데 평점 진짜 왜이리 낮지. 8점은 되야지 몰입도 쩌는데\n",
      "음... 시간만 아까웠다\n"
     ]
    }
   ],
   "source": [
    "# SentencePiece 학습용 코퍼스 파일 생성\n",
    "\n",
    "# (이전 코드에서 train_set 데이터프레임이 생성되었다고 가정합니다.)\n",
    "\n",
    "# 1. 저장할 파일 경로를 변수로 지정합니다.\n",
    "corpus_file_path = 'nsmc_corpus.txt'\n",
    "\n",
    "# 2. train_set에서 'document' 컬럼만 선택하여 .txt 파일로 저장합니다.\n",
    "# index=False와 header=False 옵션은 불필요한 인덱스와 컬럼명을 파일에 쓰지 않도록 합니다.\n",
    "train_set['document'].to_csv(corpus_file_path, index=False, header=False, encoding='utf-8')\n",
    "\n",
    "# 3. 파일 생성 확인 및 내용 일부 출력\n",
    "print(f\"✅ '{corpus_file_path}' 파일이 성공적으로 저장되었습니다.\")\n",
    "print(\"\\n[생성된 파일 내용 (상위 5줄)]\")\n",
    "\n",
    "with open(corpus_file_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "293ec9fd-187f-427c-bac3-ae0e0026daab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 모델 학습이 완료되었습니다.\n",
      "생성된 파일: nsmc_bpe_model.model, nsmc_bpe_model.vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=nsmc_corpus.txt --model_prefix=nsmc_bpe_model --vocab_size=10000 --model_type=bpe\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: nsmc_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: nsmc_bpe_model\n",
      "  model_type: BPE\n",
      "  vocab_size: 10000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: nsmc_corpus.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 116945 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=4353671\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=1707\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 116945 sentences.\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 116945\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 306969\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=87447 min_freq=79\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9385 size=20 all=101463 active=9602 piece=▁좋\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7101 size=40 all=105611 active=13750 piece=▁최\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5081 size=60 all=108890 active=17029 piece=▁여\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4228 size=80 all=112676 active=20815 piece=▁개\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3415 size=100 all=116214 active=24353 piece=▁미\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3406 min_freq=65\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2983 size=120 all=119080 active=8533 piece=▁작\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2695 size=140 all=121153 active=10606 piece=▁내용\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2310 size=160 all=123384 active=12837 piece=▁쓰레기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2159 size=180 all=125565 active=15018 piece=▁싶\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1925 size=200 all=127834 active=17287 piece=인공\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1923 min_freq=58\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1786 size=220 all=129637 active=8096 piece=다가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1664 size=240 all=132358 active=10817 piece=세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1541 size=260 all=135048 active=13507 piece=▁허\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1434 size=280 all=137246 active=15705 piece=▁이야기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1352 size=300 all=139041 active=17500 piece=▁괜찮\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1349 min_freq=52\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1260 size=320 all=140687 active=8562 piece=▁그런\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1154 size=340 all=142592 active=10467 piece=▁귀\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1113 size=360 all=143837 active=11712 piece=▁망\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1063 size=380 all=146327 active=14202 piece=였다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1007 size=400 all=148155 active=16030 piece=니까\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=996 min_freq=48\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=973 size=420 all=150257 active=9368 piece=▁애니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=940 size=440 all=152107 active=11218 piece=려고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=898 size=460 all=153597 active=12708 piece=▁인간\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=863 size=480 all=155242 active=14353 piece=▁극장\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=822 size=500 all=156449 active=15560 piece=밖에\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=822 min_freq=44\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=785 size=520 all=158200 active=9421 piece=떨어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=750 size=540 all=159589 active=10810 piece=▁여운\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=725 size=560 all=161600 active=12821 piece=▁봤다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=705 size=580 all=163806 active=15027 piece=▁약\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=688 size=600 all=165489 active=16710 piece=▁배우들\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=685 min_freq=41\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=668 size=620 all=167287 active=10043 piece=▁대사\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=646 size=640 all=168834 active=11590 piece=어야\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=621 size=660 all=170520 active=13276 piece=▁기분\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=605 size=680 all=172090 active=14846 piece=이라고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=586 size=700 all=173304 active=16060 piece=해요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=585 min_freq=38\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=569 size=720 all=174732 active=9931 piece=영화를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=550 size=740 all=176225 active=11424 piece=진다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=537 size=760 all=177522 active=12721 piece=▁남는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=523 size=780 all=178484 active=13683 piece=▁모르겠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=508 size=800 all=180266 active=15465 piece=▁싶은\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=508 min_freq=36\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=499 size=820 all=181112 active=9843 piece=▁로맨\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=488 size=840 all=182188 active=10919 piece=▁차라리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=474 size=860 all=183202 active=11933 piece=▁산\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=464 size=880 all=184151 active=12882 piece=▁C\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=451 size=900 all=184928 active=13659 piece=▁길\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=451 min_freq=34\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=441 size=920 all=186651 active=10913 piece=▁어색\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=435 size=940 all=187758 active=12020 piece=디오\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=428 size=960 all=188852 active=13114 piece=▁입\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=418 size=980 all=189825 active=14087 piece=▁배우들의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=409 size=1000 all=190860 active=15122 piece=▁환\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=409 min_freq=33\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=402 size=1020 all=191815 active=10470 piece=▁웃음\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=397 size=1040 all=192808 active=11463 piece=낭비\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=388 size=1060 all=194084 active=12739 piece=~!\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=376 size=1080 all=195067 active=13722 piece=려는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=367 size=1100 all=196268 active=14923 piece=이버\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=367 min_freq=31\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=359 size=1120 all=197089 active=10578 piece=▁감동적이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=353 size=1140 all=197916 active=11405 piece=▁봤어요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=344 size=1160 all=199357 active=12846 piece=가지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=337 size=1180 all=200095 active=13584 piece=길래\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=331 size=1200 all=201176 active=14665 piece=▁똥\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=331 min_freq=30\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=324 size=1220 all=202686 active=11486 piece=▁키\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=317 size=1240 all=203755 active=12555 piece=▁번\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=310 size=1260 all=204846 active=13646 piece=라서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=304 size=1280 all=206299 active=15099 piece=든다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=299 size=1300 all=207364 active=16164 piece=▁죄\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=299 min_freq=29\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=293 size=1320 all=208162 active=11133 piece=▁상황\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=287 size=1340 all=209531 active=12502 piece=되고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=284 size=1360 all=210523 active=13494 piece=▁c\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=281 size=1380 all=211077 active=14048 piece=▁직\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=278 size=1400 all=212023 active=14994 piece=▁영화였다\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=277 min_freq=28\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=273 size=1420 all=213065 active=11638 piece=내가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=268 size=1440 all=213805 active=12378 piece=▁쓰레기영화\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=264 size=1460 all=214822 active=13395 piece=▁평가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=258 size=1480 all=215754 active=14327 piece=▁예상\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=254 size=1500 all=216609 active=15182 piece=영화��\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=253 min_freq=27\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=249 size=1520 all=217526 active=11604 piece=았음\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=243 size=1540 all=218476 active=12554 piece=무리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=241 size=1560 all=219475 active=13553 piece=▁빨리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=239 size=1580 all=220526 active=14604 piece=▁불편\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=235 size=1600 all=221241 active=15319 piece=▁자체가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=235 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=232 size=1620 all=221766 active=11586 piece=▁주인공이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=229 size=1640 all=222786 active=12606 piece=▁상영\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=225 size=1660 all=223563 active=13383 piece=사회\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=221 size=1680 all=224278 active=14098 piece=▁감성\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=217 size=1700 all=225231 active=15051 piece=대박\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=217 min_freq=25\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=215 size=1720 all=226324 active=12225 piece=▁꿀잼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=211 size=1740 all=227096 active=12997 piece=▁창\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=209 size=1760 all=228077 active=13978 piece=히려\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=206 size=1780 all=229092 active=14993 piece=▁어쩔\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=203 size=1800 all=229762 active=15663 piece=▁놈\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=203 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=201 size=1820 all=230687 active=12381 piece=▁한마디로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=198 size=1840 all=231609 active=13303 piece=▁견\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=197 size=1860 all=232246 active=13940 piece=▁홍콩\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=194 size=1880 all=233265 active=14959 piece=한듯\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=190 size=1900 all=233861 active=15555 piece=▁끼\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=190 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=188 size=1920 all=234656 active=12458 piece=▁모르는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=185 size=1940 all=235437 active=13239 piece=함과\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=183 size=1960 all=236313 active=14115 piece=메이크\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=181 size=1980 all=236823 active=14625 piece=▁줄거리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=178 size=2000 all=237692 active=15494 piece=▁나쁜\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=178 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=176 size=2020 all=238354 active=12505 piece=▁영웅\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=174 size=2040 all=239210 active=13361 piece=▁중반\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=173 size=2060 all=240141 active=14292 piece=▁유치하고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=171 size=2080 all=241067 active=15218 piece=▁우연히\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=169 size=2100 all=241619 active=15770 piece=▁앞으로\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=168 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=167 size=2120 all=242363 active=12817 piece=▁청춘\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=165 size=2140 all=242917 active=13371 piece=있게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=164 size=2160 all=243699 active=14153 piece=▁리메이크\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=162 size=2180 all=244308 active=14762 piece=▁잘생\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=160 size=2200 all=245178 active=15632 piece=▁현재\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=160 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=158 size=2220 all=246161 active=13219 piece=▁별루\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=157 size=2240 all=246861 active=13919 piece=나온다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=155 size=2260 all=247499 active=14557 piece=새끼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=154 size=2280 all=248312 active=15370 piece=▁귀여운\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=152 size=2300 all=249299 active=16357 piece=▁누군\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=152 min_freq=21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=151 size=2320 all=249774 active=12930 piece=▁인상깊\n",
      "bpe_model_trainer.cc(268) LOG(INFO) "
     ]
    }
   ],
   "source": [
    "#SentencePiece 학습\n",
    "\n",
    "# 1. SentencePiece 라이브러리 import\n",
    "import sentencepiece as spm\n",
    "\n",
    "# 2. SentencePiece 모델 학습 실행\n",
    "# --input: 학습시킬 코퍼스 파일 경로\n",
    "# --model_prefix: 생성될 모델 파일의 이름 (접두사)\n",
    "# --vocab_size: 단어 집합의 크기\n",
    "# --model_type: 사용할 모델 타입 (예: bpe, unigram)\n",
    "spm.SentencePieceTrainer.train(\n",
    "    '--input=nsmc_corpus.txt '\n",
    "    '--model_prefix=nsmc_bpe_model '\n",
    "    '--vocab_size=10000 '\n",
    "    '--model_type=bpe'\n",
    ")\n",
    "\n",
    "print(\"\\n✅ 모델 학습이 완료되었습니다.\")\n",
    "print(\"생성된 파일: nsmc_bpe_model.model, nsmc_bpe_model.vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6671638f-23fb-40be-89c3-be4d5441d2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'이 영화 진짜 재밌네요ㅋㅋ'\n",
      "Subword Tokens: ['▁이', '▁영화', '▁진짜', '▁재밌네요', 'ᄏᄏ']\n",
      "Encoded IDs: [6, 5, 55, 1615, 9]\n",
      "------------------------------\n",
      "'돈주고 보기엔 너무 아까웠어요'\n",
      "Subword Tokens: ['▁돈주고', '▁보기엔', '▁너무', '▁아까', '웠어요']\n",
      "Encoded IDs: [1840, 2526, 25, 329, 4234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Added: freq=149 size=2340 all=250351 active=13507 piece=인은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=148 size=2360 all=251029 active=14185 piece=▁피해\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=147 size=2380 all=251608 active=14764 piece=▁메시\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=146 size=2400 all=252219 active=15375 piece=▁OST\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=146 min_freq=21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=144 size=2420 all=252787 active=13179 piece=번째\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=143 size=2440 all=253517 active=13909 piece=지않은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=142 size=2460 all=253945 active=14337 piece=▁프로그램\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=140 size=2480 all=254549 active=14941 piece=▁오락\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=139 size=2500 all=255178 active=15570 piece=▁밑에\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=139 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=138 size=2520 all=255943 active=13512 piece=▁다가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=137 size=2540 all=256718 active=14287 piece=더라도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136 size=2560 all=257320 active=14889 piece=▁케이블\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=134 size=2580 all=258079 active=15648 piece=▁12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=133 size=2600 all=258501 active=16070 piece=▁통해\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=133 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=132 size=2620 all=259110 active=13534 piece=스러움\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=130 size=2640 all=259788 active=14212 piece=▁밤\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=129 size=2660 all=260433 active=14857 piece=에서의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=128 size=2680 all=261142 active=15566 piece=▁보고싶다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=126 size=2700 all=261689 active=16113 piece=re\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=126 min_freq=19\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=125 size=2720 all=262289 active=13641 piece=▁덜\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=125 size=2740 all=262958 active=14310 piece=▁재미를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=124 size=2760 all=263613 active=14965 piece=▁그렇다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=123 size=2780 all=264271 active=15623 piece=▁설레\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=122 size=2800 all=264849 active=16201 piece=▁사는\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=122 min_freq=19\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=121 size=2820 all=265350 active=13728 piece=▁그립\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=120 size=2840 all=265933 active=14311 piece=엄마\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=120 size=2860 all=266509 active=14887 piece=▁아이들\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=119 size=2880 all=267197 active=15575 piece=▁통쾌\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=118 size=2900 all=267637 active=16015 piece=내용도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=118 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=117 size=2920 all=268345 active=14030 piece=속에서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=116 size=2940 all=269152 active=14837 piece=▁힐링\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=115 size=2960 all=269807 active=15492 piece=▁말이필요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=114 size=2980 all=270418 active=16103 piece=▁음악도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=113 size=3000 all=270962 active=16647 piece=▁만들고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=113 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=112 size=3020 all=271544 active=14126 piece=▁펑펑\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=111 size=3040 all=271977 active=14559 piece=사람은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=110 size=3060 all=272648 active=15230 piece=하시는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=109 size=3080 all=273251 active=15833 piece=▁아침\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=108 size=3100 all=273739 active=16321 piece=가슴\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=108 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=108 size=3120 all=274539 active=14422 piece=▁스스로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=107 size=3140 all=275125 active=15008 piece=영화라\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=106 size=3160 all=275802 active=15685 piece=▁되지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=105 size=3180 all=276300 active=16183 piece=▁단지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=104 size=3200 all=276629 active=16512 piece=▁농\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=104 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=103 size=3220 all=277081 active=14264 piece=▁^\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=103 size=3240 all=277646 active=14829 piece=▁타임\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=102 size=3260 all=278028 active=15211 piece=▁믿을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=101 size=3280 all=278572 active=15755 piece=와의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=100 size=3300 all=279054 active=16237 piece=▁섞\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=100 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=100 size=3320 all=279703 active=14577 piece=▁생각없이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=99 size=3340 all=280201 active=15075 piece=시간에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=98 size=3360 all=280590 active=15464 piece=▁콜\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=98 size=3380 all=281337 active=16211 piece=시키는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=97 size=3400 all=282001 active=16875 piece=▁맨날\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=97 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=96 size=3420 all=282245 active=14329 piece=▁f\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=96 size=3440 all=282981 active=15065 piece=▁나오면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=95 size=3460 all=283555 active=15639 piece=▁틀어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=94 size=3480 all=284151 active=16235 piece=져요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=94 size=3500 all=284628 active=16712 piece=▁보았다\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=94 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=93 size=3520 all=285009 active=14608 piece=아름\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=93 size=3540 all=285392 active=14991 piece=▁쓰레기같은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=92 size=3560 all=286138 active=15737 piece=▁속에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=92 size=3580 all=286656 active=16255 piece=▁러닝타임\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=91 size=3600 all=287325 active=16924 piece=처구니\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=91 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90 size=3620 all=287705 active=14734 piece=OOO\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90 size=3640 all=288098 active=15127 piece=▁박수를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=89 size=3660 all=288690 active=15719 piece=▁박진\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=88 size=3680 all=289046 active=16075 piece=이래\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=88 size=3700 all=289451 active=16480 piece=▁영화들\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=88 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87 size=3720 all=289877 active=14888 piece=회가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=86 size=3740 all=290258 active=15269 piece=니당\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=86 size=3760 all=290968 active=15979 piece=보다도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85 size=3780 all=291396 active=16407 piece=어디\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85 size=3800 all=291964 active=16975 piece=▁알바들\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=85 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84 size=3820 all=292461 active=15088 piece=▁뭐라\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84 size=3840 all=292751 active=15378 piece=▁보여준다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=83 size=3860 all=293149 active=15776 piece=에대한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=82 size=3880 all=293555 active=16182 piece=▁수고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=82 size=3900 all=293872 active=16499 piece=▁있으면\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=82 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=3920 all=294323 active=15145 piece=모두\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=3940 all=294858 active=15680 piece=▁제시\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=80 size=3960 all=295119 active=15941 piece=놈들\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=80 size=3980 all=295705 active=16527 piece=년만에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=80 size=4000 all=296189 active=17011 piece=▁있었지만\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=80 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79 size=4020 all=296691 active=15309 piece=▁대중\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79 size=4040 all=297069 active=15687 piece=▁드립니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=78 size=4060 all=297476 active=16094 piece=▁만한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=4080 all=297734 active=16352 piece=▁;\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=4100 all=298306 active=16924 piece=▁새끼\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=77 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=4120 all=298659 active=15250 piece=▁중요한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=76 size=4140 all=299169 active=15760 piece=▁아기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=76 size=4160 all=299491 active=16082 piece=▁감동적이다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=4180 all=300181 active=16772 piece=취향\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=4200 all=300398 active=16989 piece=▁한심한\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=75 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=4220 all=300837 active=15455 piece=통령\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=4240 all=301240 active=15858 piece=▁위해서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73 size=4260 all=301713 active=16331 piece=싸움\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73 size=4280 all=302139 active=16757 piece=▁뭐하나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73 size=4300 all=302315 active=16933 piece=▁말도안되는\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=72 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=4320 all=302806 active=15598 piece=▁달리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=4340 all=303168 active=15960 piece=▁명작이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=4360 all=303506 active=16298 piece=년작\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=4380 all=304081 active=16873 piece=▁책을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=4400 all=304580 active=17372 piece=▁있었는데\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=71 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70 size=4420 all=305076 active=15723 piece=▁웃고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70 size=4440 all=305441 active=16088 piece=▁연기잘\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69 size=4460 all=305781 active=16428 piece=뭥미\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69 size=4480 all=306336 active=16983 piece=▁생활\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69 size=4500 all=306588 active=17235 piece=▁떨어진다\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=69 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=4520 all=306975 active=15715 piece=장한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=4540 all=307527 active=16267 piece=▁괜찮다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=4560 all=307607 active=16347 piece=▁좋겠네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67 size=4580 all=308201 active=16941 piece=지요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67 size=4600 all=308562 active=17302 piece=애들이\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=67 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67 size=4620 all=308838 active=15650 piece=▁영화인가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=4640 all=309124 active=15936 piece=스포\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=4660 all=309669 active=16481 piece=▁위대\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=4680 all=310158 active=16970 piece=▁예쁘다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=4700 all=310573 active=17385 piece=빼고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=65 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=4720 all=311139 active=16041 piece=이었음\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=4740 all=311422 active=16324 piece=▁보기에는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=4760 all=311770 active=16672 piece=신고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=4780 all=312221 active=17123 piece=▁폐지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=4800 all=312555 active=17457 piece=▁잘봤어요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=64 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=4820 all=313152 active=16220 piece=지현\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=4840 all=313461 active=16529 piece=▁예능\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=4860 all=313772 active=16840 piece=▁실화를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=4880 all=313892 active=16960 piece=같고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=4900 all=314560 active=17628 piece=▁서부\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=62 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=4920 all=314982 active=16135 piece=▁낚였다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=4940 all=315051 active=16204 piece=▁한국인\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=4960 all=315660 active=16813 piece=스케\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=4980 all=316309 active=17462 piece=▁야한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=5000 all=316648 active=17801 piece=▁생각할\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=61 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=5020 all=316717 active=15891 piece=▁작품입니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=5040 all=317397 active=16571 piece=▁가르\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=5060 all=317660 active=16834 piece=▁별로고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=5080 all=317812 active=16986 piece=▁최고임\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=5100 all=318019 active=17193 piece=마자\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=59 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=5120 all=318520 active=16392 piece=▁이동\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=5140 all=318989 active=16861 piece=▁많은걸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=5160 all=319210 active=17082 piece=쓰레기영화\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=5180 all=319737 active=17609 piece=▁과학\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=5200 all=320035 active=17907 piece=▁프리\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=58 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=5220 all=320309 active=16260 piece=▁정도면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=5240 all=320605 active=16556 piece=아오\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=5260 all=321132 active=17083 piece=▁부르\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=5280 all=321537 active=17488 piece=지루함\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=5300 all=321781 active=17732 piece=▁이해안\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=57 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=5320 all=321942 active=16237 piece=is\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=5340 all=322487 active=16782 piece=카프\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=5360 all=322785 active=17080 piece=게하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=5380 all=323079 active=17374 piece=▁여자는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=5400 all=323204 active=17499 piece=TV\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=55 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=5420 all=323652 active=16605 piece=전혀\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=5440 all=323982 active=16935 piece=▁안될\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=5460 all=324325 active=17278 piece=있지만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=5480 all=324595 active=17548 piece=▁목소리가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=5500 all=325019 active=17972 piece=얼마\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=54 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=5520 all=325444 active=16638 piece=▁없냐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=5540 all=325771 active=16965 piece=▁네티즌\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=5560 all=325933 active=17127 piece=▁뱀파이어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=5580 all=326456 active=17650 piece=에로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=5600 all=326883 active=18077 piece=▁밀려\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=53 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=5620 all=327196 active=16644 piece=기억이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=5640 all=327453 active=16901 piece=▁제이슨\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=5660 all=327602 active=17050 piece=▁곽\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=5680 all=328161 active=17609 piece=줄은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=5700 all=328504 active=17952 piece=▁창피\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=52 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=5720 all=328862 active=16762 piece=▁되는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=5740 all=328965 active=16865 piece=▁이해불가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=5760 all=329340 active=17240 piece=살이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=5780 all=329978 active=17878 piece=후에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=5800 all=330292 active=18192 piece=습니까\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=51 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=5820 all=330555 active=16758 piece=▁명복을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=5840 all=330664 active=16867 piece=▁했더니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=5860 all=330861 active=17064 piece=▁웅\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=5880 all=331408 active=17611 piece=인게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=5900 all=331844 active=18047 piece=▁볼거\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=50 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=5920 all=332166 active=16901 piece=줬으면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=5940 all=332287 active=17022 piece=▁외계인\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=5960 all=332429 active=17164 piece=▁시작부터\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=5980 all=332684 active=17419 piece=간히\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=6000 all=333245 active=17980 piece=▁to\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=49 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=6020 all=333499 active=16910 piece=▁집어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=6040 all=333964 active=17375 piece=▁깔끔한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=6060 all=334054 active=17465 piece=▁초등학교\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=6080 all=334309 active=17720 piece=다만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=6100 all=334943 active=18354 piece=▁것만\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=48 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=6120 all=335160 active=16963 piece=▁요새\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=6140 all=335485 active=17288 piece=▁때마다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=6160 all=335633 active=17436 piece=▁다행이다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=6180 all=335702 active=17505 piece=▁쪼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=6200 all=336211 active=18014 piece=짬뽕\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=47 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=6220 all=336578 active=17152 piece=▁말투\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=6240 all=336890 active=17464 piece=점이나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=6260 all=337067 active=17641 piece=▁수준을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=6280 all=337235 active=17809 piece=▁생각해보게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=6300 all=337730 active=18304 piece=슨의\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=46 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=6320 all=338174 active=17308 piece=▁분량\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=6340 all=338456 active=17590 piece=나이트\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=6360 all=338669 active=17803 piece=▁이끌어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=6380 all=338774 active=17908 piece=▁흘러가는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=6400 all=339100 active=18234 piece=느냐\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=45 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=6420 all=339723 active=17540 piece=저런\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=6440 all=339952 active=17769 piece=▁승리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=6460 all=340224 active=18041 piece=죽이고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=6480 all=340464 active=18281 piece=▁안좋아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=6500 all=340660 active=18477 piece=▁시종일관\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=45 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=6520 all=340891 active=17264 piece=녀석\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=6540 all=341448 active=17821 piece=��이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=6560 all=341756 active=18129 piece=▁변화\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=6580 all=341978 active=18351 piece=더라고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=6600 all=342360 active=18733 piece=▁살아야\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=44 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=6620 all=342526 active=17269 piece=▁드라마로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=6640 all=342610 active=17353 piece=al\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=6660 all=343077 active=17820 piece=무시\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=6680 all=343688 active=18431 piece=판을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=6700 all=343917 active=18660 piece=▁새록\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=43 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=6720 all=344118 active=17395 piece=매이션\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=6740 all=344376 active=17653 piece=▁성룡의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=6760 all=344554 active=17831 piece=▁고등학생\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=6780 all=344642 active=17919 piece=.!\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=6800 all=344927 active=18204 piece=명한\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=42 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=6820 all=345540 active=17843 piece=집에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=6840 all=345807 active=18110 piece=▁방황\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=6860 all=346003 active=18306 piece=▁채워\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=6880 all=346362 active=18665 piece=▁바라는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=6900 all=346509 active=18812 piece=▁감독에게\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=42 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=6920 all=346661 active=17478 piece=bc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=6940 all=347237 active=18054 piece=충격\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=6960 all=347563 active=18380 piece=▁놀래\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=6980 all=347756 active=18573 piece=▁작화\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=7000 all=348175 active=18992 piece=하나요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=41 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=7020 all=348376 active=17584 piece=▁안무섭\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=7040 all=348490 active=17698 piece=▁허접하고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=7060 all=348781 active=17989 piece=망작\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=7080 all=349356 active=18564 piece=철학\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=7100 all=349574 active=18782 piece=▁수사\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=40 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=7120 all=349796 active=17683 piece=나라는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=7140 all=350197 active=18084 piece=▁관심이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=7160 all=350288 active=18175 piece=▁손가락\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=7180 all=350362 active=18249 piece=▁한동안\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=7200 all=350447 active=18334 piece=▁최고인듯\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=40 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=7220 all=350688 active=17759 piece=롭다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=7240 all=351155 active=18226 piece=진실\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=7260 all=351409 active=18480 piece=▁멋짐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=7280 all=351678 active=18749 piece=▁할때\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=7300 all=352157 active=19228 piece=한개도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=39 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=7320 all=352247 active=17683 piece=▁우려먹\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=7340 all=352387 active=17823 piece=▁긴장감은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=7360 all=352479 active=17915 piece=▁록\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=7380 all=352864 active=18300 piece=저냥\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=7400 all=353186 active=18622 piece=▁들게\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=38 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=7420 all=353360 active=17827 piece=▁입장\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=7440 all=353656 active=18123 piece=에다가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=7460 all=354030 active=18497 piece=▁나머진\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=7480 all=354095 active=18562 piece=▁유치해\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=7500 all=354193 active=18660 piece=▁미안하다\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=38 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=7520 all=354231 active=17746 piece=▁재미없었음\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=7540 all=354565 active=18080 piece=봤네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=7560 all=354992 active=18507 piece=▁강요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=7580 all=355214 active=18729 piece=▁안좋\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=7600 all=355471 active=18986 piece=못하는\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=37 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=7620 all=355836 active=18102 piece=▁관람객\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=7640 all=355935 active=18201 piece=▁액션의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=7660 all=356049 active=18315 piece=▁걸작이다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=7680 all=356178 active=18444 piece=▁이영화보고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=7700 all=356533 active=18799 piece=동이\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=36 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=7720 all=357006 active=18277 piece=전은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=7740 all=357239 active=18510 piece=▁모독\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=7760 all=357482 active=18753 piece=▁역겹\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=7780 all=357730 active=19001 piece=▁평론\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=7800 all=358159 active=19430 piece=지말자\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=36 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=7820 all=358267 active=17992 piece=▁아바타\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=7840 all=358402 active=18127 piece=보고싶은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=7860 all=358537 active=18262 piece=▁입장에서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=7880 all=358672 active=18397 piece=겨운\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=7900 all=359095 active=18820 piece=물은\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=35 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=7920 all=359621 active=18453 piece=진희\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=7940 all=359905 active=18737 piece=▁만듬\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=7960 all=360127 active=18959 piece=▁텐데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=7980 all=360547 active=19379 piece=하고도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=8000 all=360662 active=19494 piece=▁미국식\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=35 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=8020 all=360795 active=18163 piece=하더라도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=8040 all=360886 active=18254 piece=▁이어지는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=8060 all=361009 active=18377 piece=���좆\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=8080 all=361407 active=18775 piece=뒤에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=8100 all=361933 active=19301 piece=지원\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=34 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=8120 all=362245 active=18389 piece=▁대가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=8140 all=362422 active=18566 piece=▁승부\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=8160 all=362654 active=18798 piece=▁흥분\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=8180 all=362991 active=19135 piece=▁다이하\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=8200 all=363046 active=19190 piece=▁액션만\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=34 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=8220 all=363197 active=18300 piece=▁그냥저냥\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=8240 all=363253 active=18356 piece=▁한번쯤은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=8260 all=363466 active=18569 piece=끄는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=8280 all=363949 active=19052 piece=슬리\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: nsmc_bpe_model.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: nsmc_bpe_model.vocab\n"
     ]
    }
   ],
   "source": [
    "#토큰화 확인\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "# 1. 학습된 모델 파일을 로드합니다.\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('nsmc_bpe_model.model')\n",
    "\n",
    "# 2. 테스트할 샘플 문장을 준비합니다.\n",
    "sample_sentence1 = \"이 영화 진짜 재밌네요ㅋㅋ\"\n",
    "sample_sentence2 = \"돈주고 보기엔 너무 아까웠어요\"\n",
    "\n",
    "# 3. 토큰화 결과를 확인합니다.\n",
    "print(f\"'{sample_sentence1}'\")\n",
    "# encode_as_pieces: subword 단위로 분리된 토큰 리스트 반환\n",
    "print(\"Subword Tokens:\", sp.encode_as_pieces(sample_sentence1))\n",
    "# encode_as_ids: 정수 인덱스 리스트 반환\n",
    "print(\"Encoded IDs:\", sp.encode_as_ids(sample_sentence1))\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(f\"'{sample_sentence2}'\")\n",
    "print(\"Subword Tokens:\", sp.encode_as_pieces(sample_sentence2))\n",
    "print(\"Encoded IDs:\", sp.encode_as_ids(sample_sentence2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd7357c9-7d46-4beb-8b19-284661c8c8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ sp_tokenize 함수 동작 확인\n",
      "------------------------------\n",
      "원본 문장 1: 이 영화 정말 최고예요!\n",
      "토큰화 결과: tensor([   6,    5,   44,   70, 1580, 8323,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "\n",
      "원본 문장 2: 정말 재미없다. 비추.\n",
      "토큰화 결과: tensor([  44,  795, 8294, 2192, 8294,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "\n",
      "원본 문장 3: 배우들 연기력이 아까운 영화.\n",
      "토큰화 결과: tensor([ 602, 2474,  710,    5, 8294,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "\n",
      "최종 텐서의 크기: torch.Size([3, 15])\n"
     ]
    }
   ],
   "source": [
    "# sp_tokenize 함수 구현 및 테스트\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "\n",
    "# 1. 학습된 SentencePiece 모델 로드\n",
    "sp = spm.SentencePieceProcessor()\n",
    "# 이전에 학습시킨 모델 파일명을 사용합니다.\n",
    "sp.load('nsmc_bpe_model.model')\n",
    "\n",
    "# 2. sp_tokenize 함수 정의\n",
    "def sp_tokenize(processor, corpus, max_len):\n",
    "    \"\"\"\n",
    "    SentencePiece 모델을 사용하여 문장 리스트를 토큰화하고 패딩을 적용합니다.\n",
    "    \n",
    "    Args:\n",
    "        processor (SentencePieceProcessor): 로드된 SentencePiece 모델 객체\n",
    "        corpus (list of str): 토큰화할 문장들의 리스트\n",
    "        max_len (int): 모든 시퀀스의 길이를 맞출 최대 길이\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: 토큰화 및 패딩이 완료된 파이토치 텐서\n",
    "    \"\"\"\n",
    "    tokenized_sequences = []\n",
    "    for sentence in corpus:\n",
    "        # 각 문장을 정수 ID 시퀀스로 변환\n",
    "        ids = processor.encode_as_ids(sentence)\n",
    "        \n",
    "        # 패딩 또는 잘라내기\n",
    "        if len(ids) > max_len:\n",
    "            # 최대 길이를 초과하면 잘라냄\n",
    "            ids = ids[:max_len]\n",
    "        else:\n",
    "            # 최대 길이보다 짧으면 0으로 패딩 추가\n",
    "            ids += [0] * (max_len - len(ids))\n",
    "            \n",
    "        tokenized_sequences.append(ids)\n",
    "    \n",
    "    # 리스트를 파이토치 텐서로 변환\n",
    "    return torch.tensor(tokenized_sequences, dtype=torch.long)\n",
    "\n",
    "# 3. 샘플 문장으로 동작 확인\n",
    "sample_corpus = [\n",
    "    \"이 영화 정말 최고예요!\",\n",
    "    \"정말 재미없다. 비추.\",\n",
    "    \"배우들 연기력이 아까운 영화.\"\n",
    "]\n",
    "max_sequence_length = 15  # 패딩을 적용할 최대 문장 길이\n",
    "\n",
    "# 함수 호출\n",
    "token_tensor = sp_tokenize(sp, sample_corpus, max_len=max_sequence_length)\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(\"✅ sp_tokenize 함수 동작 확인\")\n",
    "print(\"-\" * 30)\n",
    "for i, sentence in enumerate(sample_corpus):\n",
    "    print(f\"원본 문장 {i+1}: {sentence}\")\n",
    "    print(f\"토큰화 결과: {token_tensor[i]}\")\n",
    "    print()\n",
    "\n",
    "print(f\"최종 텐서의 크기: {token_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "594bd695-abc9-40eb-92f8-ce9fad166498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 설계가 완료되었습니다.\n",
      "SentimentGRU(\n",
      "  (embedding): Embedding(10000, 128)\n",
      "  (gru): GRU(128, 128, num_layers=2, batch_first=True, dropout=0.6)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 1. PyTorch 라이브러리 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 2. 모델 설계: nn.Module을 상속받아 SentimentGRU 클래스 정의\n",
    "class SentimentGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        \"\"\"\n",
    "        모델의 레이어를 정의하는 생성자\n",
    "        \n",
    "        Args:\n",
    "            vocab_size (int): 단어 집합의 크기 (SentencePiece 모델의 vocab_size와 일치)\n",
    "            embedding_dim (int): 각 단어를 표현할 임베딩 벡터의 차원\n",
    "            hidden_dim (int): GRU 레이어의 은닉 상태(hidden state) 차원\n",
    "            n_layers (int): 쌓을 GRU 레이어의 개수\n",
    "            dropout (float): 드롭아웃 비율\n",
    "        \"\"\"\n",
    "        super(SentimentGRU, self).__init__()\n",
    "        \n",
    "        # --- 레이어 정의 ---\n",
    "        # 1. 임베딩 레이어: 정수 인덱스 -> 밀집 벡터\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # 2. GRU 레이어: 임베딩 벡터 시퀀스를 입력받아 문맥 정보 추출\n",
    "        # batch_first=True: 입력 텐서의 차원을 (batch_size, seq_len, embedding_dim)으로 설정\n",
    "        self.gru = nn.GRU(embedding_dim, \n",
    "                          hidden_dim, \n",
    "                          num_layers=n_layers, \n",
    "                          batch_first=True, \n",
    "                          dropout=dropout)\n",
    "        \n",
    "        # 3. 완전 연결 레이어 (Dense Layer): GRU의 최종 출력을 받아 긍정/부정을 예측\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        모델의 순전파 로직을 정의\n",
    "        데이터가 각 레이어를 거치는 순서를 결정합니다.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): 입력 데이터 (토큰화 및 패딩된 정수 시퀀스 텐서)\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: 모델의 최종 예측 결과 (logit)\n",
    "        \"\"\"\n",
    "        # --- 데이터 흐름 정의 ---\n",
    "        # x shape: (batch_size, max_len)\n",
    "        \n",
    "        # 1. 임베딩 레이어 통과\n",
    "        embedded = self.embedding(x)\n",
    "        # embedded shape: (batch_size, max_len, embedding_dim)\n",
    "        \n",
    "        # 2. GRU 레이어 통과\n",
    "        # gru_out: 모든 시점(time step)의 은닉 상태\n",
    "        # hidden: 마지막 시점의 은닉 상태\n",
    "        gru_out, hidden = self.gru(embedded)\n",
    "        # gru_out shape: (batch_size, max_len, hidden_dim)\n",
    "        # hidden shape: (n_layers, batch_size, hidden_dim)\n",
    "        \n",
    "        # 3. 마지막 시점의 출력만 선택\n",
    "        # 문장 전체의 의미를 담고 있는 마지막 단어의 출력을 사용\n",
    "        last_output = gru_out[:, -1, :]\n",
    "        # last_output shape: (batch_size, hidden_dim)\n",
    "        \n",
    "        # 4. 완전 연결 레이어 통과\n",
    "        output = self.fc(last_output)\n",
    "        # output shape: (batch_size, 1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 3. 모델 인스턴스 생성 및 구조 확인\n",
    "# --- 하이퍼파라미터 정의 ---\n",
    "VOCAB_SIZE = 10000       # SentencePiece 모델의 vocab_size와 동일해야 함\n",
    "EMBEDDING_DIM = 128      # 임베딩 벡터 차원\n",
    "HIDDEN_DIM = 128         # GRU 은닉 상태 차원\n",
    "N_LAYERS = 2             # GRU 레이어 개수\n",
    "DROPOUT = 0.6            # 드롭아웃 비율\n",
    "\n",
    "# 모델 객체 생성\n",
    "model = SentimentGRU(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT)\n",
    "\n",
    "# 모델 구조 출력\n",
    "print(\"✅ 모델 설계가 완료되었습니다.\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a05b60b5-0ba2-4184-9ade-e160087aabc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터로더 생성이 완료되었습니다.\n",
      "사용 디바이스: cuda\n",
      "\n",
      "🚀 모델 학습을 시작합니다 (조기 종료 적용)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76d439a5f844d249f7a14f036cd41e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 01/20 [Training]:   0%|          | 0/914 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/20 | Train Loss: 0.5259 | Train Acc: 71.34% | Val Loss: 0.3877 | Val Acc: 82.38%\n",
      "💡 Validation loss improved. Saving model to 'best_model.pth'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e48c77bb72425e9cb221da0b1586a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 02/20 [Training]:   0%|          | 0/914 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/20 | Train Loss: 0.3424 | Train Acc: 85.07% | Val Loss: 0.3455 | Val Acc: 84.82%\n",
      "💡 Validation loss improved. Saving model to 'best_model.pth'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f5b2b4f50d4e6f9368303fe11b85eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 03/20 [Training]:   0%|          | 0/914 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/20 | Train Loss: 0.2951 | Train Acc: 87.44% | Val Loss: 0.3459 | Val Acc: 85.19%\n",
      "⚠️ Validation loss did not improve. Patience: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95efd07a40f4a1dae200d146e5f2dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 04/20 [Training]:   0%|          | 0/914 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/20 | Train Loss: 0.2644 | Train Acc: 88.98% | Val Loss: 0.3447 | Val Acc: 85.19%\n",
      "💡 Validation loss improved. Saving model to 'best_model.pth'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a957f4658cec438a80e9f66e6dbb63ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 05/20 [Training]:   0%|          | 0/914 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/20 | Train Loss: 0.2307 | Train Acc: 90.61% | Val Loss: 0.3702 | Val Acc: 85.22%\n",
      "⚠️ Validation loss did not improve. Patience: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32199e055d9149b8ad2f32c051d9f707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 06/20 [Training]:   0%|          | 0/914 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/20 | Train Loss: 0.1903 | Train Acc: 92.49% | Val Loss: 0.4036 | Val Acc: 84.80%\n",
      "⚠️ Validation loss did not improve. Patience: 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a205cc4611a1405199f71f96c9d4f072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 07/20 [Training]:   0%|          | 0/914 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07/20 | Train Loss: 0.1463 | Train Acc: 94.52% | Val Loss: 0.4506 | Val Acc: 84.38%\n",
      "⚠️ Validation loss did not improve. Patience: 3/3\n",
      "🛑 Early stopping triggered after 7 epochs.\n",
      "\n",
      "🎉 모델 학습이 완료되었습니다. 최고 성능의 모델('best_model.pth')을 로드합니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 필요 라이브러리 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np # best_loss 초기화를 위해 import\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. 데이터 준비 및 DataLoader 생성 (이전과 동일)\n",
    "# ====================================================================================\n",
    "\n",
    "# 1-1. 하이퍼파라미터 정의\n",
    "MAX_LEN = 40\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# 1-2. 데이터셋을 토큰화하고 텐서로 변환\n",
    "X_train_tensor = sp_tokenize(sp, train_set['document'].tolist(), MAX_LEN)\n",
    "y_train_tensor = torch.tensor(train_set['label'].values, dtype=torch.float32)\n",
    "\n",
    "X_val_tensor = sp_tokenize(sp, val_set['document'].tolist(), MAX_LEN)\n",
    "y_val_tensor = torch.tensor(val_set['label'].values, dtype=torch.float32)\n",
    "\n",
    "# 1-3. DataLoader 생성\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"✅ 데이터로더 생성이 완료되었습니다.\")\n",
    "\n",
    "# ====================================================================================\n",
    "# 2. 모델 학습 및 평가 실행 (조기 종료 로직 추가)\n",
    "# ====================================================================================\n",
    "\n",
    "# 2-1. 학습 관련 하이퍼파라미터 및 설정\n",
    "EPOCHS = 20 # 최대 학습 횟수를 넉넉하게 설정\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# --- 조기 종료 관련 설정 ---\n",
    "patience = 3                 # 성능 개선을 기다릴 횟수\n",
    "patience_counter = 0         # 성능 미개선 횟수 카운터\n",
    "best_loss = np.Inf           # 초기 최저 손실값을 무한대(inf)로 설정\n",
    "best_model_path = 'best_model.pth' # 최고 성능 모델이 저장될 경로\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n",
    "print(f\"사용 디바이스: {device}\")\n",
    "print(\"\\n🚀 모델 학습을 시작합니다 (조기 종료 적용)...\")\n",
    "\n",
    "# 2-2. 학습 루프 실행\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- 훈련 단계 (이전과 동일) ---\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1:02d}/{EPOCHS} [Training]\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        preds = torch.sigmoid(outputs.squeeze()) > 0.5\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = train_correct / train_total\n",
    "\n",
    "    # --- 검증 단계 (이전과 동일) ---\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs.squeeze(), labels)\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs.squeeze()) > 0.5\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:02d}/{EPOCHS} | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy*100:.2f}% | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "    # --- 조기 종료 로직 ---\n",
    "    if avg_val_loss < best_loss:\n",
    "        # 검증 손실이 개선되면, best_loss를 업데이트하고 모델 가중치를 저장\n",
    "        best_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        patience_counter = 0 # 카운터 초기화\n",
    "        print(f\"💡 Validation loss improved. Saving model to '{best_model_path}'\")\n",
    "    else:\n",
    "        # 검증 손실이 개선되지 않으면 카운터 증가\n",
    "        patience_counter += 1\n",
    "        print(f\"⚠️ Validation loss did not improve. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        # 카운터가 지정된 횟수에 도달하면 학습 중단\n",
    "        print(f\"🛑 Early stopping triggered after {epoch+1} epochs.\")\n",
    "        break\n",
    "\n",
    "# --- 학습 종료 후 최고 성능 모델 로드 ---\n",
    "print(f\"\\n🎉 모델 학습이 완료되었습니다. 최고 성능의 모델('{best_model_path}')을 로드합니다.\")\n",
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cfa751a-de39-422d-90e7-bfb21610a297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 제거 전, test_data 개수: 50000\n",
      "document 컬럼의 결측치 수: 3\n",
      "결측치 제거 후, test_data 개수: 49997\n"
     ]
    }
   ],
   "source": [
    "# 1. 테스트 데이터셋의 결측치 확인\n",
    "print(f\"결측치 제거 전, test_data 개수: {len(test_data)}\")\n",
    "print(f\"document 컬럼의 결측치 수: {test_data['document'].isnull().sum()}\")\n",
    "\n",
    "# 2. 결측치가 있는 행 제거\n",
    "test_data.dropna(subset=['document'], inplace=True)\n",
    "\n",
    "# 3. (선택적이지만 확실한 방법) 모든 값을 문자열 타입으로 변환\n",
    "test_data['document'] = test_data['document'].astype(str)\n",
    "\n",
    "print(f\"결측치 제거 후, test_data 개수: {len(test_data)}\")\n",
    "\n",
    "# 4. 이제 sp_tokenize 함수를 호출하면 오류 없이 실행됩니다.\n",
    "X_test_tensor = sp_tokenize(sp, test_data['document'].tolist(), MAX_LEN)\n",
    "y_test_tensor = torch.tensor(test_data['label'].values, dtype=torch.float32)\n",
    "\n",
    "# DataLoader 생성\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46eea502-c265-4bee-af78-133ec15cb496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 테스트 데이터로더 생성이 완료되었습니다.\n",
      "\n",
      "🧪 모델 최종 평가를 시작합니다...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d91aef86dd40dfade2e28b7f19abaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Testing]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 모델 평가가 완료되었습니다.\n",
      "------------------------------\n",
      "  - 테스트 손실 (Loss): 0.3462\n",
      "  - 테스트 정확도 (Accuracy): 85.16%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. 필요 라이브러리 import\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. 테스트 데이터 준비 및 DataLoader 생성\n",
    "# (test_data, sp, sp_tokenize, MAX_LEN, BATCH_SIZE 변수가 이미 정의되어 있다고 가정합니다.)\n",
    "# ====================================================================================\n",
    "\n",
    "# 1-1. 테스트 데이터셋을 토큰화하고 텐서로 변환\n",
    "# DataFrame의 'document'와 'label' 컬럼을 사용합니다.\n",
    "X_test_tensor = sp_tokenize(sp, test_data['document'].tolist(), MAX_LEN)\n",
    "y_test_tensor = torch.tensor(test_data['label'].values, dtype=torch.float32)\n",
    "\n",
    "# 1-2. DataLoader 생성\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"✅ 테스트 데이터로더 생성이 완료되었습니다.\")\n",
    "\n",
    "# ====================================================================================\n",
    "# 2. 모델 평가 실행\n",
    "# (model, loss_fn, device 변수가 이미 정의되어 있다고 가정합니다.)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n🧪 모델 최종 평가를 시작합니다...\")\n",
    "\n",
    "# 2-1. 모델을 평가 모드로 설정\n",
    "# 드롭아웃 등 훈련 시에만 필요한 기능들을 비활성화합니다.\n",
    "model.eval()\n",
    "\n",
    "# 2-2. 평가 지표 초기화\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "# 2-3. 기울기 계산 비활성화\n",
    "# 메모리 사용량을 줄이고 계산 속도를 높입니다.\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"[Testing]\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # 순전파\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 손실 계산\n",
    "        loss = loss_fn(outputs.squeeze(), labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산\n",
    "        preds = torch.sigmoid(outputs.squeeze()) > 0.5\n",
    "        test_correct += (preds == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "# 2-4. 최종 성능 지표 계산\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "# 3. 최종 결과 출력\n",
    "print(\"\\n🎉 모델 평가가 완료되었습니다.\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"  - 테스트 손실 (Loss): {avg_test_loss:.4f}\")\n",
    "print(f\"  - 테스트 정확도 (Accuracy): {test_accuracy*100:.2f}%\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d240dd-d5f9-4968-8cd3-57587ba87ec4",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "- sentencepiece\n",
    "      - 테스트 손실 (Loss): 0.3462\n",
    "      - 테스트 정확도 (Accuracy): 85.16%\n",
    "- mecab\n",
    "    - 테스트 손실 (Loss): 0.3436\n",
    "    - 테스트 정확도 (Accuracy): 85.37%\n",
    "\n",
    "\n",
    "## 결론\n",
    "- 두 토크나이저의 성능 차이가 없음\n",
    "- 학습률, vocab size 등 변경을 해봤으나 현재 설정이 가장 결과가 좋았음\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
